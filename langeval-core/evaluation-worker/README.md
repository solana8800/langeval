# Evaluation Worker

## 1. Giá»›i thiá»‡u
**Evaluation Worker** lÃ  má»™t background worker chuyÃªn biá»‡t cho viá»‡c cháº¥m Ä‘iá»ƒm (Scoring) cÃ¡c tÆ°Æ¡ng tÃ¡c há»™i thoáº¡i. Service nÃ y hoáº¡t Ä‘á»™ng báº¥t Ä‘á»“ng bá»™, láº¯ng nghe yÃªu cáº§u tá»« Kafka vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh LLM-as-a-judge Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i.

## 2. Chá»©c nÄƒng chÃ­nh (Key Features)
*   **LLM-as-a-Judge**: Sá»­ dá»¥ng LLM Ä‘á»ƒ cháº¥m Ä‘iá»ƒm dá»±a trÃªn cÃ¡c metric Ä‘á»‹nh nghÄ©a trÆ°á»›c (DeepEval).
*   **Async Processing**: Xá»­ lÃ½ hÃ ng Ä‘á»£i Ä‘Ã¡nh giÃ¡ qua Kafka, Ä‘áº£m báº£o khÃ´ng cháº·n main thread cá»§a Orchestrator.
*   **Metric Support**: Há»— trá»£ cÃ¡c metric nhÆ° Faithfulness, Answer Relevancy, Hallucination, v.v.

## 3. Kiáº¿n trÃºc & CÃ´ng nghá»‡ (Technical Stack)
*   **Language**: Python 3.10+
*   **Core Library**: **DeepEval**
*   **Messaging**: Kafka Consumer (`aiokafka` / `confluent-kafka`)
*   **Communication**: Giao tiáº¿p vá»›i `Orchestrator` qua Kafka Topics.
*   **Port**: `8005` (Host) - Chá»§ yáº¿u dÃ¹ng cho Healthcheck, logic chÃ­nh cháº¡y ngáº§m.

### Project Structure
```
backend/evaluation-worker/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ consumers/              # Kafka Consumers
â”‚   â”‚   â””â”€â”€ kafka_consumer.py   # Main Consumer Loop
â”‚   â”œâ”€â”€ core/                   # Configuration
â”‚   â”‚   â””â”€â”€ config.py           # Environment Variables
â”‚   â”œâ”€â”€ models/                 # Data Schemas
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic Models
â”‚   â”œâ”€â”€ services/               # Business Logic
â”‚   â”‚   â””â”€â”€ evaluator.py        # DeepEval Integration
â”‚   â””â”€â”€ main.py                 # Entry Point
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## 4. API & Integration
Service nÃ y chá»§ yáº¿u khÃ´ng expose REST API phá»©c táº¡p mÃ  hoáº¡t Ä‘á»™ng theo mÃ´ hÃ¬nh Event-Driven.

*   `GET /health`: Health Check.

**Kafka Topics:**
*   Input: `evaluation.requests` (Nháº­n lá»‡nh cháº¥m Ä‘iá»ƒm).
*   Input: `evaluation.requests` (Nháº­n lá»‡nh cháº¥m Ä‘iá»ƒm).
*   Output: `evaluation.completed` (Tráº£ vá» káº¿t quáº£ Ä‘iá»ƒm sá»‘).
*   Output (Manual): `evaluation.manual_review` (Äáº©y ra khi Ä‘iá»ƒm tháº¥p).

## 4. Resource Service API for Manual Review
Frontend sáº½ gá»i Resource Service Ä‘á»ƒ láº¥y items tá»« queue nÃ y:
*   `GET /resource/reviews/manual-reviews`: Láº¥y danh sÃ¡ch Pending.
*   `POST /resource/reviews/manual-reviews/{id}/decision`: Duyá»‡t/Tá»« chá»‘i.

## 5. Flow hoáº¡t Ä‘á»™ng

### 5.1. Evaluation Process Flow
```mermaid
sequenceDiagram
    participant Kafka
    participant Worker as EvalWorker (Consumer)
    participant Service as Evaluator Service
    participant LLM as DeepEval/LLM
    participant Redis as Redis Cache

    Kafka->>Worker: Consume (Input, Output, Metrics)
    Worker->>Service: run_scoring(payload)
    Service->>LLM: Evaluate TestCase (LLM-as-a-Judge)
    LLM-->>Service: Score & Reason
    Service-->>Worker: EvaluationResult
    
    par Save to Redis
        Worker->>Redis: RPUSH campaign:{id}:result
    and Reply to Kafka
        Worker->>Kafka: Produce (Score Result)
    end
```

### 5.2. Data Flow Graph
```mermaid
graph TD
    KafkaIn[Kafka Topic: evaluation.requests] -->|Consume| Worker[Evaluation Worker]
    
    subgraph "Worker Process"
        Worker -->|Parse| Payload[Payload Check]
        Payload -->|Config| Evaluator[DeepEval Evaluator]
        Evaluator -->|LLM Call| API[LLM Provider / OpenAI]
        API -->|Return Score| Evaluator
    end
    
    Evaluator -->|Result| OutputHandler[Output Handler]
    
    OutputHandler -->|Push| Redis[(Redis Cache)]
    OutputHandler -->|Produce| KafkaOut[Kafka Topic: evaluation.completed]
    OutputHandler -.->|"Callback (Optional)"| Langfuse[Langfuse Trace]
    
    style KafkaIn fill:#f9f9f9,stroke:#333
    style Worker fill:#e1f5ff,stroke:#333
    style Redis fill:#fff4e6,stroke:#333
    style KafkaOut fill:#f9f9f9,stroke:#333
```

### 5.3. Service Dependencies
```mermaid
graph TB
    Orch[Orchestrator] -->|Produce Event| Kafka[Kafka]
    Kafka -->|Consume| Worker[Evaluation Worker]
    
    Worker -->|LLM Call| LLM[LLM Provider]
    Worker -->|Push Result| Redis[(Redis)]
    Worker -.->|Push Trace| Langfuse[Langfuse]
    
    Worker -->|Produce Result| Kafka
    
    style Worker fill:#e1f5ff
    style Kafka fill:#f9f9f9
    style Redis fill:#fff4e6
    style LLM fill:#eedece
    style Langfuse fill:#f3e5f5
```

## 6. Tráº¡ng thÃ¡i phÃ¡t triá»ƒn (Status)
> **Tráº¡ng thÃ¡i: ğŸŸ¢ Production Ready (v1.0)**

### âœ… ÄÃ£ hoÃ n thiá»‡n (Completed)
*   [x] **Architecture Refactoring**: 
    *   Chuyá»ƒn Ä‘á»•i sang cáº¥u trÃºc MVC modular vá»›i cÃ¡c layer rÃµ rÃ ng (Consumer, Service, Model).
    *   Code dá»… maintain vÃ  má»Ÿ rá»™ng.
*   [x] **Core Evaluation Engine**: 
    *   TÃ­ch há»£p DeepEval framework thÃ nh cÃ´ng.
    *   Há»— trá»£ cÃ¡c metrics chuáº©n: Faithfulness, Answer Relevancy, Hallucination Detection.
    *   LLM-as-a-Judge sá»­ dá»¥ng OpenAI/DeepSeek Ä‘á»ƒ cháº¥m Ä‘iá»ƒm tá»± Ä‘á»™ng.
*   [x] **Async Processing**: 
    *   Kafka Consumer vá»›i aiokafka xá»­ lÃ½ message báº¥t Ä‘á»“ng bá»™.
    *   Batch Processing (batch size: 10) Ä‘á»ƒ tá»‘i Æ°u throughput.
    *   Non-blocking I/O Ä‘áº£m báº£o hiá»‡u nÄƒng cao.
*   [x] **Reliability & Persistence**: 
    *   Redis caching cho káº¿t quáº£ evaluation (key pattern: `campaign:{id}:result`).
    *   Retry mechanism vá»›i exponential backoff khi LLM API timeout.
    *   Error handling toÃ n diá»‡n, khÃ´ng crash khi gáº·p lá»—i.
*   [x] **Human-in-the-loop (FR-05)**:
    *   Confidence Threshold Check (máº·c Ä‘á»‹nh: 0.5).
    *   Tá»± Ä‘á»™ng route cÃ¡c item cÃ³ Ä‘iá»ƒm tháº¥p hoáº·c confidence tháº¥p vÃ o queue `evaluation.manual_review`.
    *   Metadata tracking Ä‘á»ƒ frontend hiá»ƒn thá»‹ lÃ½ do cáº§n review.
*   [x] **Langfuse Integration**:
    *   Push trace data vÃ o Langfuse Ä‘á»ƒ theo dÃµi quÃ¡ trÃ¬nh evaluation.
    *   Callback mechanism ghi láº¡i toÃ n bá»™ LLM calls.
*   [x] **Docker Deployment**:
    *   Dockerfile vÃ  docker-compose configuration hoÃ n chá»‰nh.
    *   Service cháº¡y á»•n Ä‘á»‹nh vá»›i replicas support.
*   [x] **Red Teaming Evaluation (FR-04)**:
    *   Safety Metrics implementation (Toxicity, PII Leakage, Bias Detection).
    *   Severity classification logic (Critical, High, Medium, Low).
    *   Refusal detection Ä‘á»ƒ trÃ¡nh false positives.
    *   Automated vulnerability assessment cho adversarial attacks.

### ğŸ”„ Äang phÃ¡t triá»ƒn / Roadmap
1.  **Metric Expansion**:
    *   [ ] Custom Metrics cho cÃ¡c domain cá»¥ thá»ƒ (Code Quality, Compliance, Safety).
    *   [ ] Support cho user-defined metrics qua configuration.
2.  **Performance Optimization**:
    *   [ ] Parallel evaluation cho multiple test cases.
    *   [ ] Caching LLM responses Ä‘á»ƒ giáº£m cost vÃ  latency.
3.  **Dashboard Integration**:
    *   [ ] Real-time metrics streaming qua WebSocket.
    *   [ ] API endpoints Ä‘á»ƒ frontend pull aggregated metrics tá»« Redis/ClickHouse.

### ğŸ”— Dependencies
```toml
[tool.poetry.dependencies]
python = "^3.10"
fastapi = "^0.104.0"
aiokafka = "^0.8.1"
deepeval = "^0.21.0"
redis = "^5.0.1"
pydantic-settings = "^2.0.0"
```

## 7. Testing & TDD

We follow the **Test Driven Development (TDD)** approach.

### 1. Framework
*   **Pytest**: Main testing framework.
*   **DeepEval Mocks**: Avoid calling real OpenAI API for unit tests.

### 2. Test Structure
```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_metrics_logic.py # Verify custom metric formulas
â”‚   â””â”€â”€ test_faithfulness.py  # Mocked Hallucination checks
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_kafka_consumer.py
â”‚   â””â”€â”€ test_redis_push.py
â””â”€â”€ conftest.py
```

### 3. Detailed Test Scenarios (from BRD)
| Category | Scenario | Expected Outcome |
| :--- | :--- | :--- |
| **Metric Accuracy** | **Answer Relevancy** (Metric) | Input: "What is 2+2?", Output: "Paris is capital of France". Score MUST be < 0.2. |
| | **Faithfulness** (RAG) | Input Context: "Apple is red". Output: "Apple is blue". Score MUST be 0.0 (Hallucination detected). |
| **Performance** | **Batch Evaluation** | Process 50 test cases. Total time < 2 minutes (using Async Batching). |
| **Error Handling** | LLM API Timeout | System MUST retry 3 times (Exponential Backoff) before marking as ERROR. |
| **Logic** | **Low Confidence** (FR-05) | If score between 0.3 - 0.5, Flag as `NEEDS_HUMAN_REVIEW` in Metadata. |

### 4. Running Tests
```bash
pytest
```
