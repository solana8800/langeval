# Data Ingestion Service

## 1. Giá»›i thiá»‡u
**Data Ingestion Service** lÃ  cá»•ng tiáº¿p nháº­n dá»¯ liá»‡u tá»‘c Ä‘á»™ cao (High-throughput) cá»§a há»‡ thá»‘ng. ÄÆ°á»£c viáº¿t báº±ng **Rust**, service nÃ y Ä‘áº£m báº£o viá»‡c thu tháº­p Log vÃ  Trace tá»« cÃ¡c nguá»“n khÃ¡c nhau (Kafka) vÃ  ghi xuá»‘ng cÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¢n tÃ­ch (ClickHouse) má»™t cÃ¡ch hiá»‡u quáº£ nháº¥t.

## 2. Chá»©c nÄƒng chÃ­nh (Key Features)
*   **High Performance Ingestion**: TiÃªu thá»¥ message tá»« Kafka vá»›i Ä‘á»™ trá»… tháº¥p.
*   **Batch Processing**: Gom nhÃ³m (Batching) dá»¯ liá»‡u trÆ°á»›c khi insert vÃ o ClickHouse Ä‘á»ƒ tá»‘i Æ°u I/O.
*   **Protocol Buffers / JSON Parsing**: Xá»­ lÃ½ Ä‘á»‹nh dáº¡ng dá»¯ liá»‡u Log/Trace phá»©c táº¡p.

## 3. Kiáº¿n trÃºc & CÃ´ng nghá»‡ (Technical Stack)
*   **Language**: **Rust**
*   **Web Framework**: Actix-web (cho Healthcheck / Metrics endpoint)
*   **Kafka Client**: `rdkafka` (Rust wrapper for librdkafka)
*   **Database**: ClickHouse (via HTTP/Native interface)
*   **Port**: `8008` (Host) / `8080` (Container)

## 4. API Endpoints
Service chá»§ yáº¿u cháº¡y background task, chá»‰ expose endpoint quáº£n trá»‹:

| Method | Endpoint | MÃ´ táº£ |
| :--- | :--- | :--- |
| `GET` | `/health` | Health Check. Tráº£ vá» status service vÃ  version Rust. |

## 5. Flow hoáº¡t Ä‘á»™ng

### Service Flow Diagram

```mermaid
sequenceDiagram
    participant Kafka
    participant Ingestion as Data Ingestion Service
    participant Buffer as Internal Batch Buffer
    participant ClickHouse

    Kafka->>Ingestion: Consume Message (Trace/Log)
    Ingestion->>Ingestion: Parse JSON/Protobuf
    Ingestion->>Buffer: Add to Batch
    
    loop Every 5s or 1000 items
        Buffer->>ClickHouse: Bulk Insert (Async HTTP)
        ClickHouse-->>Buffer: Acknowledge
        Buffer->>Buffer: Clear Batch
    end
```

### Data Flow Graph

```mermaid
flowchart LR
    K[Kafka Topic: traces] -->|Consume| C[Consumer Worker]
    C -->|Deserialize| P[Parser]
    P -->|Struct| B[Batch Buffer]
    B -->|Time/Size Trigger| F[Flusher]
    F -->|INSERT INTO traces| CH[(ClickHouse)]
    
    subgraph Service[Data Ingestion Service]
        C
        P
        B
        F
    end
```

### Service Dependencies

```mermaid
graph TD
    App[Data Ingestion Service]
    
    subgraph Infrastructure
        Kafka["Kafka (Message Queue)"]
        ClickHouse["ClickHouse (Analytics DB)"]
    end
    
    App -->|Consume| Kafka
    App -->|Batch Write| ClickHouse
    
    subgraph Frameworks
        App --> Actix["Actix-web (API)"]
        App --> RdKafka["RdKafka (Consumer)"]
    end
```

## 6. Tráº¡ng thÃ¡i phÃ¡t triá»ƒn (Status)
> **Tráº¡ng thÃ¡i: ðŸŸ¡ Äang phÃ¡t triá»ƒn (In Progress)**

### âœ… ÄÃ£ hoÃ n thiá»‡n (Done)
*   [x] **Core Framework**: 
    *   Actix-web server khá»Ÿi táº¡o thÃ nh cÃ´ng vá»›i Runtime báº¥t Ä‘á»“ng bá»™.
    *   Healthcheck endpoint `/health` hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh.
*   [x] **Kafka Integration**:
    *   Consumer loop sá»­ dá»¥ng `rdkafka` Ä‘Ã£ Ä‘Æ°á»£c implement.
    *   Káº¿t ná»‘i tá»›i Kafka cluster vÃ  consume messages tá»« topic `traces`.
    *   Auto-commit Ä‘Æ°á»£c báº­t Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng máº¥t message.
*   [x] **Database (ClickHouse)**:
    *   HTTP Client (`db.rs`) káº¿t ná»‘i tá»›i ClickHouse thÃ nh cÃ´ng.
    *   Batch Insert logic Ä‘Ã£ hoÃ n thiá»‡n vá»›i trigger theo size (1000 items) hoáº·c time (5s).
    *   Async HTTP insert Ä‘á»ƒ tá»‘i Æ°u throughput.
*   [x] **Observability**:
    *   Prometheus metrics endpoint táº¡i `/metrics` expose cÃ¡c chá»‰ sá»‘ cÆ¡ báº£n.
    *   Health Check endpoint tráº£ vá» status vÃ  version.
    *   Logging vá»›i `env_logger` ghi láº¡i cÃ¡c event quan trá»ng.
*   [x] **Docker Integration**:
    *   Dockerfile Ä‘Ã£ Ä‘Æ°á»£c táº¡o vÃ  tÃ­ch há»£p vÃ o docker-compose.
    *   Service cháº¡y á»•n Ä‘á»‹nh trong container environment.

### ðŸ”„ Äang phÃ¡t triá»ƒn (In Progress)
*   [ ] **Parsing Logic Enhancement**: 
    *   Hiá»‡n táº¡i service chá»‰ nháº­n raw string tá»« Kafka.
    *   Äang thiáº¿t káº¿ schema Ä‘á»ƒ parse JSON/Protobuf chi tiáº¿t.
    *   Cáº§n map chÃ­nh xÃ¡c vÃ o cÃ¡c cá»™t trong ClickHouse (trace_id, span_id, input, output, latency, cost).

### âš ï¸ ChÆ°a hoÃ n thiá»‡n (TODO)
*   [ ] **Reliability / Error Handling**:
    *   Hiá»‡n táº¡i lá»—i insert chá»‰ log ra console, khÃ´ng cÃ³ retry mechanism.
    *   Cáº§n implement Dead Letter Queue (DLQ) - cÃ³ thá»ƒ lÃ  file local hoáº·c Kafka topic riÃªng.
    *   Cáº§n exponential backoff cho retry logic.
*   [ ] **Configuration Management**: 
    *   Batch Size, Flush Interval Ä‘ang hardcode trong code.
    *   Cáº§n externalize ra Environment Variables Ä‘á»ƒ dá»… Ä‘iá»u chá»‰nh.
*   [ ] **Graceful Shutdown**: 
    *   ChÆ°a xá»­ lÃ½ signal SIGTERM/SIGINT Ä‘Ãºng cÃ¡ch.
    *   Cáº§n flush háº¿t batch Ä‘ang pending trÆ°á»›c khi táº¯t service.
*   [ ] **Monitoring & Alerting**:
    *   Cáº§n thÃªm metrics chi tiáº¿t: batch_size, flush_duration, error_rate.
    *   TÃ­ch há»£p vá»›i Grafana dashboard Ä‘á»ƒ visualize.

## 7. Testing & TDD (Planned)

> **Note**: Hiá»‡n táº¡i source code (`src/`) chÆ°a bao gá»“m cÃ¡c file test. Káº¿ hoáº¡ch testing dÆ°á»›i Ä‘Ã¢y sáº½ Ä‘Æ°á»£c triá»ƒn khai trong giai Ä‘oáº¡n tiáº¿p theo.

### 1. Framework
*   **Rust Built-in Test**: `cargo test` is the primary tool.
*   **Testcontainers**: For spawning ephemeral Kafka/ClickHouse containers.

### 2. Planned Test Structure
```
data-ingestion/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs
â”‚   â””â”€â”€ batcher.rs       # Unit tests for Batching Logic
â”œâ”€â”€ tests/               # Integration Tests
â”‚   â”œâ”€â”€ common/
â”‚   â”‚   â””â”€â”€ mod.rs       # Setup Docker Containers
â”‚   â””â”€â”€ test_flow.rs     # Full End-to-End Flow
â””â”€â”€ Cargo.toml
```

### 3. Key Test Scenarios
| Category | Scenario | Expected Outcome |
| :--- | :--- | :--- |
| **Logic** | **Batch Trigger (Size)** | Send 1000 logs > Buffer Size. System MUST flush multiple times. |
| | **Batch Trigger (Time)** | Send 1 log and wait > timeout. System MUST flush. |
| **Parsing** | **Malformed JSON** | Input: `{"invalid":json"}`. System MUST log error and NOT crash. |
| **Integration** | **ClickHouse Insert** | Verify data inserted into `traces` table matches input JSON. |

### 4. Running Tests (Future)
```bash
# Run unit tests
cargo test --lib

# Run integration tests (requires Docker)
cargo test --test test_flow
```
