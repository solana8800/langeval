# Gen AI Service

## 1. Giá»›i thiá»‡u
**Gen AI Service** táº­n dá»¥ng sá»©c máº¡nh cá»§a Generative AI Ä‘á»ƒ tá»± Ä‘á»™ng sinh dá»¯ liá»‡u kiá»ƒm thá»­, giÃºp giáº£m thiá»ƒu cÃ´ng sá»©c cáº¥u hÃ¬nh thá»§ cÃ´ng. Service nÃ y cÃ³ kháº£ nÄƒng táº¡o ra cÃ¡c Persona (nhÃ¢n váº­t giáº£ láº­p) vÃ  Test Cases tá»« tÃ i liá»‡u nghiá»‡p vá»¥.

## 2. Chá»©c nÄƒng chÃ­nh (Key Features)
*   **Persona Generation**: Sinh cÃ¡c nhÃ¢n váº­t giáº£ láº­p (User Personas) vá»›i tÃ­nh cÃ¡ch, má»¥c tiÃªu vÃ  hÃ nh vi cá»¥ thá»ƒ dá»±a trÃªn ngá»¯ cáº£nh (VD: "KhÃ¡ch hÃ ng khÃ³ tÃ­nh", "NgÆ°á»i dÃ¹ng má»›i").
*   **Test Case Generation**: Sinh cÃ¡c ká»‹ch báº£n test (Input prompts) dá»±a trÃªn Persona vÃ  tÃ i liá»‡u.
*   **Synthetic Data**: Há»— trá»£ táº¡o dá»¯ liá»‡u giáº£ láº­p (Goldens) cho RAG Testing.

## 3. Kiáº¿n trÃºc & CÃ´ng nghá»‡ (Technical Stack)
*   **Language**: Python 3.10+
*   **Framework**: FastAPI
*   **AI Logic**: `LangChain`, `OpenAI API`
*   **Port**: `8000` (Host - Updated code runs on 8000)

## 4. Cáº¥u TrÃºc ThÆ° Má»¥c (Code Structure)

MÃ£ nguá»“n Ä‘Ã£ Ä‘Æ°á»£c refactor theo cáº¥u trÃºc modular Ä‘á»ƒ dá»… dÃ ng má»Ÿ rá»™ng vÃ  báº£o trÃ¬:

```
backend/gen-ai-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes/         # Chá»©a API routes (gen_ai.py)
â”‚   â”œâ”€â”€ core/               # Core logic, utils (logging, config)
â”‚   â”œâ”€â”€ models/             # Pydantic models (Schemas)
â”‚   â”œâ”€â”€ services/           # Business logic (LLM Generators)
â”‚   â””â”€â”€ main.py             # Entry point
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

## 5. API Endpoints

> **Interactive API Documentation:** [https://api.langeval.space/gen-ai/docs](https://api.langeval.space/gen-ai/docs)

| Method | Endpoint | MÃ´ táº£ |
| :--- | :--- | :--- |
| `GET` | `/health` | Health Check. |
| `POST` | `/generate/personas` | Sinh danh sÃ¡ch Persona. Input: `count`, `context`. |
| `POST` | `/generate/test-cases` | Sinh danh sÃ¡ch Test Cases cho má»™t Persona cá»¥ thá»ƒ. |

## 6. Diagrams (Quy trÃ¬nh hoáº¡t Ä‘á»™ng)

### Process Flow (State Diagram)

HÃ nh trÃ¬nh xá»­ lÃ½ má»™t request Ä‘iá»ƒn hÃ¬nh:

```mermaid
stateDiagram-v2
    [*] --> Idle
    Idle --> ReceivingRequest : API Call
    ReceivingRequest --> Validating : Pydantic Validate
    Validating --> Processing : Valid
    Validating --> Error : Invalid
    Processing --> BuildingPrompt : Template + Context
    BuildingPrompt --> InvokingLLM : API Request
    InvokingLLM --> ParsingOutput : Response Received
    ParsingOutput --> Completed : Success
    ParsingOutput --> Error : Parse Fail
    Completed --> Returning : API Response
    Returning --> Idle
    Error --> Returning : Error Response
```

### Data Flow Graph

Luá»“ng dá»¯ liá»‡u giá»¯a cÃ¡c thÃ nh pháº§n:

```mermaid
flowchart LR
    User[Client] -->|Request Data| API[API Interface]
    API -->|Validated Data| Service[Generator Service]
    Service -->|Prompt Template| LLM[LLM Provider]
    LLM -->|Raw Completion| Parser[Output Parser]
    Parser -->|Structured JSON| API
    API -->|Response| User
```

### Sequence Diagram (Chi tiáº¿t tÆ°Æ¡ng tÃ¡c)

```mermaid
sequenceDiagram
    participant Client
    participant API as API Router
    participant Service as Generator Service
    participant LLM as LLM Provider (DeepSeek)

    Client->>API: POST /generate/personas
    API->>Service: generate_personas(count, context)
    Service->>LLM: Prompt (LangChain)
    LLM-->>Service: JSON Response
    Service-->>API: List[Persona]
    API-->>Client: {"personas": [...]}
```

### Class Diagram (Models)

```mermaid
classDiagram
    class PersonaRequest {
        +int count
        +str context
    }
    class TestCaseRequest {
        +dict persona
        +str context
    }
    class Persona {
        +str name
        +int age
        +str job
        +str pain_points
    }
    
    PersonaRequest ..> Persona : generates
    TestCaseRequest --> Persona : uses
```

### Service Dependencies

```mermaid
graph TD
    Service[Gen AI Service]
    Service -->|Framework| FastAPI[FastAPI]
    Service -->|Validation| Pydantic[Pydantic]
    Service -->|LLM Framework| LangChain[LangChain]
    Service -->|External API| OpenAI[OpenAI / DeepSeek API]
    
    subgraph Core Logic
        FastAPI
        Pydantic
    end
    
    subgraph AI Logic
        LangChain
        OpenAI
    end
```

## 7. HÆ°á»›ng dáº«n cháº¡y (Getting Started)

### Local Development

```bash
# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Cháº¡y server
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

### Docker

```bash
docker build -t gen-ai-service .
docker run -p 8000:8000 gen-ai-service
```

## 8. Tráº¡ng thÃ¡i phÃ¡t triá»ƒn (Status)
> **Tráº¡ng thÃ¡i: ðŸŸ¢ Production Ready (v1.0)**

### âœ… ÄÃ£ hoÃ n thiá»‡n (Completed Features)
*   [x] **Core Framework**: 
    *   FastAPI application vá»›i modular structure (api/routes, services, models, core).
    *   LangChain integration cho LLM orchestration.
    *   Pydantic models cho validation vÃ  type safety.
*   [x] **Persona Generation**: 
    *   API endpoint `/generate/personas` sinh nhÃ¢n váº­t giáº£ láº­p tá»« context.
    *   Há»— trá»£ customize sá»‘ lÆ°á»£ng personas vÃ  business context.
    *   Output format chuáº©n vá»›i name, age, job, pain_points.
*   [x] **Test Case Generation**: 
    *   API endpoint `/generate/test-cases` sinh ká»‹ch báº£n test tá»± Ä‘á»™ng.
    *   Dá»±a trÃªn persona vÃ  context Ä‘á»ƒ táº¡o test cases phÃ¹ há»£p.
    *   Evolutionary generation Ä‘á»ƒ táº¡o variations phá»©c táº¡p.
*   [x] **RAG Integration (FR-03)**:
    *   PDF Upload & Parsing sá»­ dá»¥ng `PyMuPDF` (`PyPDFLoader`).
    *   Vector Store vá»›i `ChromaDB` cho semantic search.
    *   Document chunking vá»›i configurable strategy.
    *   **Storage Integration**: Upload file lÃªn **MinIO/S3** (`app/core/storage.py`).
    *   Generate QA pairs tá»« PDF documents vá»›i context preservation.
*   [x] **Prompt Optimization (FR-07)**: 
    *   Thuáº­t toÃ¡n GEPA implementation (`app/services/optimizer.py`).
    *   Tá»± Ä‘á»™ng tá»‘i Æ°u prompt qua multiple generations.
    *   Scoring mechanism Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ prompt quality.
*   [x] **Docker Deployment**:
    *   Dockerfile vá»›i Python 3.10 slim base.
    *   Environment variables configuration.
    *   TÃ­ch há»£p vÃ o docker-compose stack.

### ðŸ”„ Äang phÃ¡t triá»ƒn / Roadmap
1.  **Synthetic Data Quality Metrics**:
    *   [ ] TÃ­ch há»£p DeepEval Ä‘á»ƒ tá»± cháº¥m Ä‘iá»ƒm cháº¥t lÆ°á»£ng dá»¯ liá»‡u sinh ra.
    *   [ ] Self-check mechanism trÆ°á»›c khi return data cho user.
    *   [ ] Quality threshold configuration.
2.  **Advanced RAG Integration**:
    *   [ ] Hybrid Search (Keyword + Vector) Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chuáº©n xÃ¡c.
    *   [ ] Re-ranking results vá»›i cross-encoder models.
    *   [ ] Multi-document synthesis cho complex scenarios.
3.  **Enhanced Prompt Optimization**:
    *   [ ] Upgrade lÃªn MIPROv2 algorithm.
    *   [ ] A/B testing framework cho prompt variations.
    *   [ ] Automatic prompt versioning vÃ  rollback.

## 9. Testing & TDD

We follow the **Test Driven Development (TDD)** approach.

### 1. Framework
*   **Pytest**: Main testing framework.
*   **LangChain Eval**: For evaluating prompt outputs quality.

### 2. Test Structure
```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_synthesizer.py  # Test evolutionary logic (DeepEval)
â”‚   â”œâ”€â”€ test_pdf_parser.py   # Test PyPDFLoader
â”‚   â””â”€â”€ test_prompt_opt.py   # Test GEPA/MIPROv2 algorithms
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_openai_api.py   # Mocked OpenAI responses
â”‚   â””â”€â”€ test_s3_upload.py    # MinIO persistence
â””â”€â”€ conftest.py
```

### 3. Detailed Test Scenarios (from BRD)
| Category | Scenario | Expected Outcome |
| :--- | :--- | :--- |
| **Synthetic Data** | **Evolutionary Generation** (FR-03) | Given a simple question "What is AI?", System MUST generate 5 complex variations (Adding constraints, reasoning). |
| | **RAG Context** | Upload PDF. Generated QA pair MUST be verifiable against text chunks in PDF. |
| **Prompt Opt** | **GEPA Algorithm** | (FR-07) Run 10 generations of prompt mutation. Final prompt score MUST be > Initial prompt score. |
| **Integration** | **S3 Upload** | Upload 50MB PDF. File MUST appear in MinIO bucket `raw-documents`. |

### 4. Running Tests
```bash
pytest
```
