# Báº¯t Ä‘áº§u
# TrÆ°á»ng há»£p sá»­ dá»¥ng
# RAG

## HÆ°á»›ng dáº«n nhanh vá» ÄÃ¡nh giÃ¡ RAG

Há»c cÃ¡ch Ä‘Ã¡nh giÃ¡ cÃ¡c há»‡ thá»‘ng vÃ  pipeline retrieval-augmented-generation (RAG) báº±ng cÃ¡ch sá»­ dá»¥ng `deepeval`, cháº³ng háº¡n nhÆ° RAG QA, trÃ¬nh tÃ³m táº¯t (summarizers), vÃ  chatbot há»— trá»£ khÃ¡ch hÃ ng.

## Tá»•ng Quan

ÄÃ¡nh giÃ¡ RAG liÃªn quan Ä‘áº¿n viá»‡c Ä‘Ã¡nh giÃ¡ retriever (bá»™ truy xuáº¥t) vÃ  generator (bá»™ táº¡o) nhÆ° cÃ¡c thÃ nh pháº§n riÃªng biá»‡t. Äiá»u nÃ y lÃ  do trong má»™t pipeline RAG, Ä‘áº§u ra cuá»‘i cÃ¹ng chá»‰ tá»‘t báº±ng bá»‘i cáº£nh mÃ  báº¡n Ä‘Ã£ náº¡p vÃ o LLM cá»§a mÃ¬nh.

**Trong hÆ°á»›ng dáº«n nhanh 5 phÃºt nÃ y, báº¡n sáº½ há»c cÃ¡ch:**

*   ÄÃ¡nh giÃ¡ pipeline RAG cá»§a báº¡n end-to-end
*   Kiá»ƒm thá»­ retriever vÃ  generator nhÆ° cÃ¡c thÃ nh pháº§n riÃªng biá»‡t
*   ÄÃ¡nh giÃ¡ RAG nhiá»u lÆ°á»£t

## Äiá»u Kiá»‡n TiÃªn Quyáº¿t

*   CÃ i Ä‘áº·t `deepeval`
*   Má»™t khÃ³a API Confident AI (Ä‘Æ°á»£c khuyáº¿n nghá»‹). ÄÄƒng kÃ½ má»™t cÃ¡i [táº¡i Ä‘Ã¢y.](https://app.confident-ai.com)

:::info
Confident AI cho phÃ©p báº¡n xem vÃ  chia sáº» cÃ¡c bÃ¡o cÃ¡o kiá»ƒm thá»­ cá»§a mÃ¬nh. Äáº·t khÃ³a API cá»§a báº¡n trong CLI:

```bash
CONFIDENT_API_KEY="confident_us..."
```
:::

## Cháº¡y ÄÃ¡nh GiÃ¡ RAG Äáº§u TiÃªn Cá»§a Báº¡n

ÄÃ¡nh giÃ¡ RAG end-to-end coi toÃ n bá»™ á»©ng dá»¥ng LLM cá»§a báº¡n nhÆ° má»™t pipeline RAG Ä‘á»™c láº­p. Trong `deepeval`, má»™t tÆ°Æ¡ng tÃ¡c má»™t lÆ°á»£t vá»›i pipeline RAG cá»§a báº¡n Ä‘Æ°á»£c mÃ´ hÃ¬nh hÃ³a nhÆ° má»™t LLM test case:

![LLM Test Case](../images/d28073bd.png)

`retrieval_context` trong sÆ¡ Ä‘á»“ trÃªn lÃ  ráº¥t quan trá»ng, vÃ¬ nÃ³ Ä‘áº¡i diá»‡n cho cÃ¡c Ä‘oáº¡n vÄƒn báº£n (text chunks) Ä‘Ã£ Ä‘Æ°á»£c truy xuáº¥t táº¡i thá»i Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡.

:::note
`deepeval` cung cáº¥p nhiá»u lá»±a chá»n mÃ´ hÃ¬nh LLM mÃ  báº¡n cÃ³ thá»ƒ dá»… dÃ ng chá»n vÃ  cháº¡y Ä‘Ã¡nh giÃ¡ cÃ¹ng.

*   OpenAI
*   Anthropic
*   Gemini
*   Ollama
*   Grok
*   Azure OpenAI
*   Amazon Bedrock
*   Vertex AI

```python
from deepeval.metrics import AnswerRelevancyMetric

task_completion_metric = AnswerRelevancyMetric(model="gpt-4.1")
```

(CÃ¡c vÃ­ dá»¥ khÃ¡c tÆ°Æ¡ng tá»± cho cÃ¡c model khÃ¡c...)
:::

### Thiáº¿t láº­p pipeline RAG

Sá»­a Ä‘á»•i pipeline RAG cá»§a báº¡n Ä‘á»ƒ tráº£ vá» cÃ¡c bá»‘i cáº£nh Ä‘Ã£ truy xuáº¥t cÃ¹ng vá»›i pháº£n há»“i cá»§a LLM.

*   Python
*   LangGraph
*   LangChain
*   LlamaIndex

```python
def rag_pipeline(input):
   ...
   return 'RAG output', ['retrieved context 1', 'retrieved context 2', ...]
```

`main.py` (vÃ­ dá»¥ LangChain)

```python
from langchain_core.messages import HumanMessage
from langchain.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI

embeddings = OpenAIEmbeddings()
vectorstore = FAISS.load_local("./faiss_index", embeddings)
retriever = vectorstore.as_retriever()
llm = ChatOpenAI(model="gpt-4")

def rag_pipeline(input):
    # TrÃ­ch xuáº¥t bá»‘i cáº£nh truy xuáº¥t
    retrieved_docs = retriever.get_relevant_documents(input)
    context_texts = [doc.page_content for doc in retrieved_docs]

    # Táº¡o pháº£n há»“i
    state = {"messages": [HumanMessage(content=input + "\\n\\n".join(context_texts))]}
    result = llm.invoke(state)
    return result["messages"][-1].content, context_texts
```

(CÃ¡c vÃ­ dá»¥ mÃ£ khÃ¡c cho LlamaIndex... váº«n giá»¯ nguyÃªn)

:::info
Thay vÃ¬ thay Ä‘á»•i mÃ£ cá»§a báº¡n Ä‘á»ƒ tráº£ vá» dá»¯ liá»‡u nÃ y, chÃºng tÃ´i sáº½ chá»‰ cho báº¡n má»™t cÃ¡ch tá»‘t hÆ¡n Ä‘á»ƒ cháº¡y cÃ¡c Ä‘Ã¡nh giÃ¡ RAG trong pháº§n tiáº¿p theo.
:::

### Táº¡o má»™t test case

Táº¡o má»™t test case sá»­ dá»¥ng bá»‘i cáº£nh truy xuáº¥t vÃ  Ä‘áº§u ra LLM tá»« pipeline RAG cá»§a báº¡n. TÃ¹y chá»n cung cáº¥p má»™t Ä‘áº§u ra mong Ä‘á»£i náº¿u báº¡n Ä‘á»‹nh sá»­ dá»¥ng cÃ¡c sá»‘ liá»‡u [contextual precision](/docs/metrics-contextual-precision) vÃ  [contextual recall](/docs/metrics-contextual-recall).

```python
from deepeval.test_case import LLMTestCase

input = 'How do I purchase tickets to a Coldplay concert?'
actual_output, retrieved_contexts = rag_pipeline(input)

test_case = LLMTestCase(
    input=input,
    actual_output=actual_output,
    retrieval_context=retrieved_contexts,
    expected_output='optional expected output'
)
```

### XÃ¡c Ä‘á»‹nh cÃ¡c sá»‘ liá»‡u

XÃ¡c Ä‘á»‹nh cÃ¡c sá»‘ liá»‡u RAG Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ pipeline RAG cá»§a báº¡n, hoáº·c xÃ¡c Ä‘á»‹nh sá»‘ liá»‡u riÃªng cá»§a báº¡n báº±ng cÃ¡ch sá»­ dá»¥ng [G-Eval](/docs/metrics-llm-evals).

```python
from deepeval.metrics import AnswerRelevancyMetric, ContextualPrecisionMetric

answer_relevancy = AnswerRelevancyMetric(threshold=0.8)
contextual_precision = ContextualPrecisionMetric(threshold=0.8)
```

**CÃ³ nhá»¯ng sá»‘ liá»‡u RAG nÃ o?**

DeepEval cung cáº¥p tá»•ng cá»™ng 5 sá»‘ liá»‡u RAG, Ä‘Ã³ lÃ :

*   [Answer Relevancy](/docs/metrics-answer-relevancy)
*   [Faithfulness](/docs/metrics-faithfulness)
*   [Contextual Relevancy](/docs/metrics-contextual-relevancy)
*   [Contextual Precision](/docs/metrics-contextual-precision)
*   [Contextual Recall](/docs/metrics-contextual-recall)

Má»—i sá»‘ liá»‡u Ä‘o lÆ°á»ng má»™t [tham sá»‘ khÃ¡c nhau](/guides/guides-rag-evaluation) trong cháº¥t lÆ°á»£ng pipeline RAG cá»§a báº¡n, vÃ  má»—i sá»‘ liá»‡u cÃ³ thá»ƒ giÃºp báº¡n xÃ¡c Ä‘á»‹nh cÃ¡c prompt, mÃ´ hÃ¬nh hoáº·c cÃ i Ä‘áº·t retriever tá»‘t nháº¥t cho trÆ°á»ng há»£p sá»­ dá»¥ng cá»§a báº¡n.

### Cháº¡y má»™t Ä‘Ã¡nh giÃ¡

Cháº¡y má»™t Ä‘Ã¡nh giÃ¡ trÃªn LLM test case báº¡n Ä‘Ã£ táº¡o trÆ°á»›c Ä‘Ã³ báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c sá»‘ liá»‡u Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh á»Ÿ trÃªn.

`main.py`

```python
from deepeval import evaluate
...

evaluate([test_case], metrics=[answer_relevancy, contextual_precision])
```

ğŸ‰ğŸ¥³ **ChÃºc má»«ng!** Báº¡n vá»«a cháº¡y Ä‘Ã¡nh giÃ¡ RAG Ä‘áº§u tiÃªn cá»§a mÃ¬nh. ÄÃ¢y lÃ  nhá»¯ng gÃ¬ Ä‘Ã£ xáº£y ra:

*   Khi báº¡n gá»i `evaluate()`, `deepeval` cháº¡y táº¥t cáº£ cÃ¡c `metrics` cá»§a báº¡n Ä‘á»‘i vá»›i táº¥t cáº£ cÃ¡c `test_cases`
*   Táº¥t cáº£ cÃ¡c `metrics` xuáº¥t ra má»™t Ä‘iá»ƒm sá»‘ giá»¯a `0-1`, vá»›i má»™t `ngÆ°á»¡ng` máº·c Ä‘á»‹nh lÃ  `0.5`
*   CÃ¡c sá»‘ liá»‡u nhÆ° `contextual_precision` Ä‘Ã¡nh giÃ¡ dá»±a trÃªn `retrieval_context`, trong khi `answer_relevancy` kiá»ƒm tra `actual_output` cá»§a test case cá»§a báº¡n
*   Má»™t test case chá»‰ vÆ°á»£t qua náº¿u táº¥t cáº£ cÃ¡c sá»‘ liá»‡u Ä‘á»u vÆ°á»£t qua

Äiá»u nÃ y táº¡o ra má»™t láº§n cháº¡y kiá»ƒm thá»­, lÃ  má»™t "báº£n chá»¥p"/benchmark cá»§a pipeline RAG cá»§a báº¡n táº¡i báº¥t ká»³ thá»i Ä‘iá»ƒm nÃ o.

### Xem trÃªn Confident AI (Ä‘Æ°á»£c khuyáº¿n nghá»‹)

Náº¿u báº¡n Ä‘Ã£ Ä‘áº·t `CONFIDENT_API_KEY`, cÃ¡c láº§n cháº¡y kiá»ƒm thá»­ sáº½ xuáº¥t hiá»‡n tá»± Ä‘á»™ng trÃªn [Confident AI](https://app.confident-ai.com), ná»n táº£ng DeepEval.

[](https://deepeval-docs.s3.us-east-1.amazonaws.com/getting-started%3Arag.mp4)

:::tip
Náº¿u báº¡n chÆ°a Ä‘Äƒng nháº­p, báº¡n váº«n cÃ³ thá»ƒ táº£i lÃªn láº§n cháº¡y kiá»ƒm thá»­ lÃªn Confident AI tá»« bá»™ nhá»› Ä‘á»‡m cá»¥c bá»™:

```bash
deepeval view
```
:::

## ÄÃ¡nh GiÃ¡ Retriever

`deepeval` cho phÃ©p báº¡n Ä‘Ã¡nh giÃ¡ cÃ¡c thÃ nh pháº§n RAG riÃªng láº». Äiá»u nÃ y cÅ©ng cÃ³ nghÄ©a lÃ  báº¡n khÃ´ng pháº£i tráº£ vá» `retrieval_context` á»Ÿ nhá»¯ng nÆ¡i khÃ³ xá»­ chá»‰ Ä‘á»ƒ náº¡p dá»¯ liá»‡u vÃ o hÃ m `evaluate()`.

### Trace retriever cá»§a báº¡n

Gáº¯n decorator `@observe` vÃ o cÃ¡c hÃ m/phÆ°Æ¡ng thá»©c táº¡o nÃªn retriever cá»§a báº¡n. Nhá»¯ng cÃ¡i nÃ y sáº½ Ä‘áº¡i diá»‡n cho cÃ¡c thÃ nh pháº§n riÃªng láº» trong pipeline RAG cá»§a báº¡n.

```python
from deepeval.tracing import observe

@observe()
def retriever(input):
    # Triá»ƒn khai retriever cá»§a báº¡n á»Ÿ Ä‘Ã¢y
    pass
```

:::important
Äáº·t `CONFIDENT_TRACE_FLUSH=1` trong CLI cá»§a báº¡n Ä‘á»ƒ ngÄƒn traces bá»‹ máº¥t trong trÆ°á»ng há»£p chÆ°Æ¡ng trÃ¬nh káº¿t thÃºc sá»›m.

```bash
export CONFIDENT_TRACE_FLUSH=1
```
:::

### XÃ¡c Ä‘á»‹nh cÃ¡c sá»‘ liá»‡u & test case

Táº¡o má»™t sá»‘ liá»‡u táº­p trung vÃ o retriever. Sau Ä‘Ã³ báº¡n sáº½ cáº§n:

1.  ThÃªm nÃ³ vÃ o thÃ nh pháº§n cá»§a báº¡n
2.  Táº¡o má»™t `LLMTestCase` trong thÃ nh pháº§n Ä‘Ã³ vá»›i `retrieval_context`

```python
from deepeval.tracing import observe, update_current_span
from deepeval.metrics import ContextualRelevancyMetric

contextual_relevancy = ContextualRelevancyMetric(threshold=0.6)

@observe(metrics=[contextual_relevancy])
def retriever(query):
    # Triá»ƒn khai retriever cá»§a báº¡n á»Ÿ Ä‘Ã¢y
    update_current_span(
        test_case=LLMTestCase(input=query, retrieval_context=["..."])
    )
    pass
```

### Cháº¡y má»™t Ä‘Ã¡nh giÃ¡

Cuá»‘i cÃ¹ng, sá»­ dá»¥ng iterator `dataset` Ä‘á»ƒ gá»i há»‡ thá»‘ng RAG cá»§a báº¡n trÃªn má»™t danh sÃ¡ch cÃ¡c goldens.

```python
from deepeval.dataset import EvaluationDataset, Golden
...

# Táº¡o bá»™ dá»¯ liá»‡u
dataset = EvaluationDataset(goldens=[Golden(input='This is a test query')])

# Láº·p qua bá»™ dá»¯ liá»‡u
for golden in dataset.evals_iterator():
    retriever(golden.input)
```

âœ… Xong. Vá»›i thiáº¿t láº­p nÃ y, má»™t vÃ²ng láº·p for Ä‘Æ¡n giáº£n lÃ  táº¥t cáº£ nhá»¯ng gÃ¬ cáº§n thiáº¿t.

:::tip
Báº¡n cÅ©ng cÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ retriever cá»§a mÃ¬nh náº¿u nÃ³ Ä‘Æ°á»£c lá»“ng trong má»™t pipeline RAG:

```python
from deepeval.dataset import EvaluationDataset, Golden
...

def rag_pipeline(query):
    @observe(metrics=[contextual_relevancy])
    def retriever(query):
        pass

# Táº¡o bá»™ dá»¯ liá»‡u
dataset = EvaluationDataset(goldens=[Golden(input='This is a test query')])

# Láº·p qua bá»™ dá»¯ liá»‡u
for golden in dataset.evals_iterator():
    rag_pipeline(golden.input)
```
:::

## ÄÃ¡nh GiÃ¡ Generator

Äiá»u tÆ°Æ¡ng tá»± cÅ©ng Ã¡p dá»¥ng cho viá»‡c Ä‘Ã¡nh giÃ¡ generator cá»§a pipeline RAG cá»§a báº¡n, chá»‰ láº§n nÃ y báº¡n sáº½ trace generator cá»§a mÃ¬nh vá»›i cÃ¡c sá»‘ liá»‡u táº­p trung vÃ o generator cá»§a báº¡n thay tháº¿.

### Trace generator cá»§a báº¡n

Gáº¯n decorator `@observe` vÃ o cÃ¡c hÃ m/phÆ°Æ¡ng thá»©c táº¡o nÃªn generator cá»§a báº¡n:

```python
from deepeval.tracing import observe

@observe()
def generator(query):
    # Triá»ƒn khai generator cá»§a báº¡n á»Ÿ Ä‘Ã¢y
    pass
```

### XÃ¡c Ä‘á»‹nh cÃ¡c sá»‘ liá»‡u & test case

Táº¡o má»™t sá»‘ liá»‡u táº­p trung vÃ o generator. Sau Ä‘Ã³ báº¡n sáº½ cáº§n:

1.  ThÃªm nÃ³ vÃ o thÃ nh pháº§n cá»§a báº¡n
2.  Táº¡o má»™t `LLMTestCase` vá»›i cÃ¡c tham sá»‘ báº¯t buá»™c

VÃ­ dá»¥, `FaithfulnessMetric` yÃªu cáº§u `retrieval_context`, trong khi `AnswerRelevancyMetric` thÃ¬ khÃ´ng.

```python
from deepeval.tracing import observe, update_current_span
from deepeval.metrics import AnswerRelevancyMetric

answer_relevancy = AnswerRelevancyMetric(threshold=0.6)

@observe(metrics=[answer_relevancy])
def generator(query, text_chunks):
    # Triá»ƒn khai generator cá»§a báº¡n á»Ÿ Ä‘Ã¢y
    update_current_span(test_case=LLMTestCase(input=query, actual_output="..."))
    pass
```

### Cháº¡y má»™t Ä‘Ã¡nh giÃ¡

Cuá»‘i cÃ¹ng, sá»­ dá»¥ng iterator `dataset` Ä‘á»ƒ gá»i há»‡ thá»‘ng RAG cá»§a báº¡n trÃªn má»™t danh sÃ¡ch cÃ¡c goldens.

```python
from deepeval.dataset import EvaluationDataset, Golden
...

# Táº¡o bá»™ dá»¯ liá»‡u
dataset = EvaluationDataset(goldens=[Golden(input='This is a test query')])

# Láº·p qua bá»™ dá»¯ liá»‡u
for golden in dataset.evals_iterator():
    generator(golden.input)
```

âœ… Xong. Báº¡n vá»«a há»c cÃ¡ch Ä‘Ã¡nh giÃ¡ generator nhÆ° má»™t thÃ nh pháº§n Ä‘á»™c láº­p.

:::info
Báº¡n cÅ©ng cÃ³ thá»ƒ káº¿t há»£p Ä‘Ã¡nh giÃ¡ retriever vÃ  generator:

```python
from deepeval.dataset import EvaluationDataset, Golden
...

def rag_pipeline(query):
    @observe(metrics=[contextual_relevancy])
    def retriever(query) -> list[str]:
        update_current_span(test_case=LLMTestCase(input=query, retrieval_context=["..."]))

    @observe(metrics=[answer_relevancy])
    def generator(query, text_chunks):
        update_current_span(test_case=LLMTestCase(input=query, actual_output="..."))

    text_chunks = retriever(query)
    return generator(query, text_chunks)

# Táº¡o bá»™ dá»¯ liá»‡u
dataset = EvaluationDataset(goldens=[Golden(input='This is a test query')])

# Láº·p qua bá»™ dá»¯ liá»‡u
for golden in dataset.evals_iterator():
    rag_pipeline(golden.input)
```
:::

[](https://deepeval-docs.s3.us-east-1.amazonaws.com/getting-started%3Arag-evals%3Acomponent.mp4)

## ÄÃ¡nh GiÃ¡ RAG Nhiá»u LÆ°á»£t

`deepeval` cÅ©ng cho phÃ©p báº¡n Ä‘Ã¡nh giÃ¡ RAG trong cÃ¡c há»‡ thá»‘ng nhiá»u lÆ°á»£t. Äiá»u nÃ y Ä‘áº·c biá»‡t há»¯u Ã­ch cho cÃ¡c chatbot dá»±a vÃ o RAG Ä‘á»ƒ táº¡o pháº£n há»“i, cháº³ng háº¡n nhÆ° chatbot há»— trá»£ khÃ¡ch hÃ ng.

:::note
TrÆ°á»›c tiÃªn báº¡n nÃªn Ä‘á»c [pháº§n nÃ y](/docs/getting-started-chatbots) vá» Ä‘Ã¡nh giÃ¡ nhiá»u lÆ°á»£t náº¿u báº¡n chÆ°a Ä‘á»c.
:::

### Táº¡o má»™t test case

Táº¡o má»™t `ConversationalTestCase` báº±ng cÃ¡ch truyá»n vÃ o danh sÃ¡ch cÃ¡c `Turn` tá»« má»™t cuá»™c há»™i thoáº¡i hiá»‡n cÃ³, tÆ°Æ¡ng tá»± nhÆ° Ä‘á»‹nh dáº¡ng tin nháº¯n cá»§a OpenAI.

```python
from deepeval.test_case import ConversationalTestCase, Turn

test_case = ConversationalTestCase(
    turns=[
        Turn(role="user", content="I'd like to buy a ticket to a Coldplay concert."),
        Turn(
            role="assistant",
            content="Great! I can help you with that. Which city would you like to attend?",
            retrieval_context=["Concert cities: New York, Los Angeles, Chicago"]
        ),
        Turn(role="user", content="New York, please."),
        Turn(
            role="assistant",
            content="Perfect! I found VIP and standard tickets for the Coldplay concert in New York. Which one would you like?",
            retrieval_context=["VIP ticket details", "Standard ticket details"]
        )
    ]
)
```

VÃ¬ chatbot cá»§a báº¡n sá»­ dá»¥ng RAG, má»—i lÆ°á»£t tá»« trá»£ lÃ½ (assistant) cÅ©ng nÃªn bao gá»“m tham sá»‘ `retrieval_context`.

### Táº¡o cÃ¡c sá»‘ liá»‡u

XÃ¡c Ä‘á»‹nh má»™t sá»‘ liá»‡u RAG nhiá»u lÆ°á»£t Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ há»‡ thá»‘ng chatbot cá»§a báº¡n:

```python
from deepeval.metrics import TurnRelevancy, TurnFaithfulness
from deepeval.test_case import TurnParams

turn_faithfulness = TurnFaithfulness()
turn_relevancy = TurnRelevancy()
```

### Cháº¡y má»™t Ä‘Ã¡nh giÃ¡

Cháº¡y má»™t Ä‘Ã¡nh giÃ¡ trÃªn test case sá»­ dá»¥ng hÃ m `evaluate` vÃ  sá»‘ liá»‡u RAG há»™i thoáº¡i mÃ  báº¡n Ä‘Ã£ xÃ¡c Ä‘á»‹nh.

`main.py`

```python
from deepeval import evaluate
...

evaluate([test_case], metrics=[turn_faithfulness, turn_relevancy])
```

Cuá»‘i cÃ¹ng, cháº¡y `main.py`:

```bash
python main.py
```

âœ… Xong. CÃ³ ráº¥t nhiá»u chi tiáº¿t chÃºng tÃ´i Ä‘Ã£ bá» qua trong pháº§n nhiá»u lÆ°á»£t nÃ y, cháº³ng háº¡n nhÆ° cÃ¡ch mÃ´ phá»ng tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng, báº¡n cÃ³ thá»ƒ tÃ¬m hiá»ƒu thÃªm [táº¡i Ä‘Ã¢y.](/docs/getting-started-chatbots)

[](https://deepeval-docs.s3.us-east-1.amazonaws.com/getting-started%3Arag-evals%3Aconversation.mp4)

## CÃ¡c BÆ°á»›c Tiáº¿p Theo

BÃ¢y giá» báº¡n Ä‘Ã£ cháº¡y cÃ¡c Ä‘Ã¡nh giÃ¡ RAG Ä‘áº§u tiÃªn cá»§a mÃ¬nh, báº¡n nÃªn:

1.  **TÃ¹y chá»‰nh cÃ¡c sá»‘ liá»‡u cá»§a báº¡n**: Bao gá»“m táº¥t cáº£ 5 [sá»‘ liá»‡u RAG](/docs/metrics-introduction) dá»±a trÃªn trÆ°á»ng há»£p sá»­ dá»¥ng cá»§a báº¡n.
2.  **Chuáº©n bá»‹ má»™t bá»™ dá»¯ liá»‡u**: Náº¿u báº¡n khÃ´ng cÃ³, hÃ£y [táº¡o má»™t bá»™](/docs/synthesizer-introduction) lÃ m Ä‘iá»ƒm khá»Ÿi Ä‘áº§u.
3.  **KÃ­ch hoáº¡t Ä‘Ã¡nh giÃ¡ trong production**: Chá»‰ cáº§n thay tháº¿ `metrics` trong `@observe` báº±ng chuá»—i [`metric_collection`](https://www.confident-ai.com/docs/llm-tracing/evaluations#online-evaluations) trÃªn Confident AI.

Báº¡n sáº½ cÃ³ thá»ƒ phÃ¢n tÃ­ch hiá»‡u suáº¥t theo thá»i gian trÃªn cÃ¡c **threads** theo cÃ¡ch nÃ y, vÃ  thÃªm chÃºng trá»Ÿ láº¡i vÃ o bá»™ dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ cá»§a báº¡n Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ thÃªm.

[](https://confident-docs.s3.us-east-1.amazonaws.com/llm-tracing:traces.mp4)

**ÄÃ¡nh GiÃ¡ RAG trong Production**

[Chá»‰nh sá»­a trang nÃ y](https://github.com/confident-ai/deepeval/edit/main/docs/docs/getting-started-rag.mdx)

Cáº­p nháº­t láº§n cuá»‘i vÃ o **9 thÃ¡ng 1, 2026** bá»Ÿi **Jeffrey Ip**
