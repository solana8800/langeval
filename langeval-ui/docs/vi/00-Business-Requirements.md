# BUSINESS REQUIREMENTS DOCUMENT (BRD)
**Project Name**: Enterprise AI Agent Evaluation Platform
**Version**: 1.1 (Comprehensive Master)
**Date**: 2026-01-21
**Status**: DRAFT FOR APPROVAL

---

## 0. KI·ªÇM SO√ÅT T√ÄI LI·ªÜU (Document Control)

### 0.1. L·ªãch s·ª≠ Thay ƒë·ªïi (Revision History)
| Version | Date | Description of Changes | Author |
| :--- | :--- | :--- | :--- |
| 1.0 | 2026-01-20 | Kh·ªüi t·∫°o t√†i li·ªáu (Draft ƒë·∫ßu ti√™n). | TuanTD |
| 1.1 | 2026-01-21 | B·ªï sung chu·∫©n h√≥a c·∫•u tr√∫c: Scope, Stakeholders, NFR, Glossary. | TuanTD |

### 0.2. Ph√™ duy·ªát (Sign-off)
| Role | Name | Signature | Date |
| :--- | :--- | :--- | :--- |
| Project Sponsor | [TBD] | | |
| Product Owner | [TBD] | | |
| Technical Lead | [TBD] | | |

## 0.3. THU·∫¨T NG·ªÆ & VI·∫æT T·∫ÆT (Glossary & Acronyms)
| Term/Acronym | Definition |
| :--- | :--- |
| **BRD** | Business Requirements Document - T√†i li·ªáu y√™u c·∫ßu nghi·ªáp v·ª•. |
| **LLM** | Large Language Model - M√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (v√≠ d·ª•: GPT-4, Claude 3). |
| **RAG** | Retrieval-Augmented Generation - K·ªπ thu·∫≠t b·ªï sung d·ªØ li·ªáu ngo√†i cho LLM. |
| **Agent** | H·ªá th·ªëng AI c√≥ kh·∫£ nƒÉng t·ª± ch·ªß, s·ª≠ d·ª•ng c√¥ng c·ª• ƒë·ªÉ th·ª±c hi·ªán t√°c v·ª•. |
| **MCP** | Model Context Protocol - Chu·∫©n k·∫øt n·ªëi gi·ªØa LLM v√† d·ªØ li·ªáu/c√¥ng c·ª•. |
| **SSO** | Single Sign-On - ƒêƒÉng nh·∫≠p m·ªôt l·∫ßn (S·ª≠ d·ª•ng Google OAuth). |
| **RBAC** | Role-Based Access Control - Ph√¢n quy·ªÅn d·ª±a tr√™n vai tr√≤. |
| **Workspace** | Kh√¥ng gian l√†m vi·ªác chung cho m·ªôt Project ho·∫∑c Team. |
| **NFR** | Non-Functional Requirements - Y√™u c·∫ßu phi ch·ª©c nƒÉng. |
| **PII** | Personally Identifiable Information - Th√¥ng tin ƒë·ªãnh danh c√° nh√¢n. |
| **EaaS** | Evaluation-as-a-Service - M√¥ h√¨nh cung c·∫•p d·ªãch v·ª• ƒë√°nh gi√° AI. |

---

## 1. T·ªîNG QUAN D·ª∞ √ÅN (Executive Summary)

### 1.1. B·ªëi c·∫£nh & V·∫•n ƒë·ªÅ (Problem Statement)
*   **Th·ª±c tr·∫°ng**: C√°c doanh nghi·ªáp ƒëang tri·ªÉn khai AI Agents ph·ª©c t·∫°p (Stateful, Tool-using, RAG) nh∆∞ng quy tr√¨nh QA v·∫´n d·ª´ng l·∫°i ·ªü vi·ªác check th·ªß c√¥ng ho·∫∑c d√πng c√°c b·ªô test c·ª©ng nh·∫Øc (Static Datasets).
*   **Pain Points**:
    *   **Automation Gap**: Kh√¥ng th·ªÉ test t·ª± ƒë·ªông c√°c k·ªãch b·∫£n h·ªôi tho·∫°i d√†i (Multi-turn conversations) n∆°i Agent c√≥ th·ªÉ ƒëi sai h∆∞·ªõng ·ªü b·∫•t k·ª≥ b∆∞·ªõc n√†o.
    *   **Black Box Risk**: Kh√¥ng ƒëo l∆∞·ªùng ƒë∆∞·ª£c "T·∫°i sao" AI tr·∫£ l·ªùi nh∆∞ v·∫≠y (thi·∫øu Tracing/Reasoning).
    *   **Safety Risks**: R·ªßi ro cao v·ªÅ Jailbreak, Prompt Injection, PII Leakage khi ƒë∆∞a ra Public.
    *   **Metric Ambiguity**: Thi·∫øu b·ªô ti√™u chu·∫©n ƒë·ªãnh l∆∞·ª£ng (Hallucination Rate < 5%, Relevance > 0.9).

### 1.2. M·ª•c ti√™u Chi·∫øn l∆∞·ª£c (Strategic Goals)
1.  **Active Evaluation**: Chuy·ªÉn t·ª´ Passive Monitoring (ch·ªù log) sang Active Testing (gi·∫£ l·∫≠p User t·∫•n c√¥ng).
2.  **Full Automation**: T·ª± ƒë·ªông h√≥a 100% quy tr√¨nh t·ª´ sinh Test Case -> Ch·∫°y Test -> Ch·∫•m ƒëi·ªÉm -> B√°o c√°o.
3.  **Measurable Quality**: Chu·∫©n h√≥a ch·∫•t l∆∞·ª£ng AI b·∫±ng c√°c con s·ªë (Metrics) c·ª• th·ªÉ.
4.  **Dev-QC Collaboration**: Cung c·∫•p c√¥ng c·ª• cho c·∫£ Developer (Unit Test) v√† QC (No-Code Testing).

### 1.3. Ph·∫°m vi D·ª± √°n (Project Scope)

#### In-Scope (Trong ph·∫°m vi)
*   X√¢y d·ª±ng n·ªÅn t·∫£ng ƒë√°nh gi√° AI t·∫≠p trung (AI Evaluation Platform).
*   T√≠ch h·ª£p c√°c engine: LangGraph (Orchestration), AutoGen (Simulation), DeepEval (Evaluation), Langfuse (Observability).
*   PhaÃÅt tri√™Ãân giao di·ªán Web App (AI Studio) cho QC t·∫°o test case d·∫°ng No-code (keÃÅo thaÃâ).
*   H·ªó tr·ª£ test c√°c lo·∫°i Bot: Chatbot CSKH, RAG Bot, Agent th·ª±c hi·ªán t√°c v·ª•.
*   T·∫°o b√°o c√°o t·ª± ƒë·ªông (HTML, PDF) v√† Dashboard theo d√µi realtime.

#### Out-of-Scope (Ngo√†i ph·∫°m vi - Giai ƒëo·∫°n n√†y)
*   T·ª± x√¢y d·ª±ng LLM ri√™ng (Foundation Model Training).
*   H·ªó tr·ª£ ƒë√°nh gi√° Video/Audio chuy√™n s√¢u (ngo√†i ph·∫°m vi Multimodal c∆° b·∫£n c·ªßa GPT-4o).
*   Can thi·ªáp tr·ª±c ti·∫øp v√†o m√£ ngu·ªìn s·∫£n ph·∫©m Bot (ch·ªâ t∆∞∆°ng t√°c qua API/Black-box testing).
*   Qu·∫£n l√Ω h·∫° t·∫ßng deployment cho c√°c Bot target (V·∫•n ƒë·ªÅ c·ªßa DevOps, kh√¥ng ph·∫£i c·ªßa h·ªá th·ªëng Eval).

### 1.4. C√°c b√™n li√™n quan (Stakeholders)
| Role | Responsibility | Representatives |
| :--- | :--- | :--- |
| **Project Sponsor** | Cung c·∫•p ng√¢n s√°ch, ph√™ duy·ªát ƒë·ªãnh h∆∞·ªõng chi·∫øn l∆∞·ª£c. | CFO / CTO |
| **Product Owner** | ƒê·ªãnh nghƒ©a y√™u c·∫ßu, ∆∞u ti√™n backlog, nghi·ªám thu s·∫£n ph·∫©m. | Head of Product |
| **Development Team** | X√¢y d·ª±ng h·ªá th·ªëng Eval Platform, t√≠ch h·ª£p SDK. | AI Engineers, Backend/Frontend Devs |
| **QA/Tester** | Ng∆∞·ªùi d√πng ch√≠nh, t·∫°o test case, v·∫≠n h√†nh h·ªá th·ªëng ƒë√°nh gi√°. | QC Leaders, Testers |
| **End Users (Target)** | C√°c Developer ph√°t tri·ªÉn Bot s·ª≠ d·ª•ng h·ªá th·ªëng ƒë·ªÉ t·ª± test. | AI Devs c·ªßa c√°c team d·ª± √°n kh√°c |

### 1.5. Gi·∫£ ƒë·ªãnh & R√†ng bu·ªôc (Assumptions & Constraints)

#### Gi·∫£ ƒë·ªãnh (Assumptions)
*   **H·∫° t·∫ßng**: Ng∆∞·ªùi d√πng doanh nghi·ªáp ƒë√£ c√≥ s·∫µn h·∫° t·∫ßng ƒë·ªÉ deploy Docker (n·∫øu d√πng Self-hosted) ho·∫∑c ch·∫•p nh·∫≠n s·ª≠ d·ª•ng Cloud.
*   **API Keys**: Ng∆∞·ªùi d√πng cung c·∫•p API Key c·ªßa c√°c LLM (OpenAI, Anthropic) ƒë·ªÉ ch·∫°y test.
*   **D·ªØ li·ªáu**: Kh√°ch h√†ng c√≥ s·∫µn c√°c t√†i li·ªáu nghi·ªáp v·ª• (PDF, Docx) ƒë·ªÉ l√†m ƒë·∫ßu v√†o cho vi·ªác sinh d·ªØ li·ªáu test.

#### R√†ng bu·ªôc (Constraints)
*   **T√†i nguy√™n & H·∫°n m·ª©c (Quotas)**: Gi·ªõi h·∫°n t√≠nh nƒÉng v√† dung l∆∞·ª£ng s·ª≠ d·ª•ng t√πy thu·ªôc v√†o g√≥i ƒëƒÉng k√Ω c·ªßa ng∆∞·ªùi d√πng (Free, Pro, Enterprise).
*   **Ng√¢n s√°ch API**: Chi ph√≠ token cho LLM do ng∆∞·ªùi d√πng nh·∫≠p API Key t·ª± chi tr·∫£, tuy nhi√™n gi·ªõi h·∫°n s·ªë l∆∞·ª£t request s·∫Ω ƒë∆∞·ª£c h·ªá th·ªëng ch·∫∑n d·ª±a tr√™n Plan ƒë·ªÉ b·∫£o v·ªá c∆° s·ªü h·∫° t·∫ßng chung.
*   **C√¥ng ngh·ªá**: H·ªá th·ªëng core ƒë∆∞·ª£c x√¢y d·ª±ng b·∫±ng Python (Backend) v√† React/Next.js (Frontend).
*   **Performance**: V·ªõi c√°c b√†i test d√†i (Multi-turn Agent), th·ªùi gian ch·∫°y c√≥ th·ªÉ k√©o d√†i t·ª´ v√†i ph√∫t ƒë·∫øn v√†i gi·ªù t√πy ƒë·ªô ph·ª©c t·∫°p.

---

## 2. PH√ÇN T√çCH K·ª∏ THU·∫¨T CHUY√äN S√ÇU (Technical Architecture & Rationale)

T·∫°i sao ch·ªçn b·ªô "Quad-Core" c√¥ng ngh·ªá n√†y? Ph√¢n t√≠ch l·ª£i th·∫ø c·∫°nh tranh.

### 2.1. Orchestration: LangGraph (vs. LangChain Chains)
*   **Vai tr√≤**: ƒêi·ªÅu ph·ªëi lu·ªìng ch·∫°y test.
*   **L√Ω do ch·ªçn**: H·ªó tr·ª£ **Cyclic Graphs** (V√≤ng l·∫∑p).
*   **Gi·∫£i th√≠ch**: Trong ki·ªÉm th·ª≠ Agent, n·∫øu Agent l√†m sai (Agent Fail), ta c·∫ßn m·ªôt c∆° ch·∫ø "T·ª± s·ª≠a sai" (Self-Correction Loop). LangChain c≈© ch·ªâ ch·∫°y th·∫≥ng (DAG), kh√¥ng quay l·∫°i ƒë∆∞·ª£c. LangGraph cho ph√©p ƒë·ªãnh nghƒ©a c√°c node `Check -> Fail -> Retry` c·ª±c k·ª≥ linh ho·∫°t.

### 2.2. Simulation: Microsoft AutoGen (vs. CrewAI)
*   **Vai tr√≤**: Gi·∫£ l·∫≠p ng∆∞·ªùi d√πng v√† m√¥i tr∆∞·ªùng.
*   **L√Ω do ch·ªçn**: Ki·∫øn tr√∫c **Conversable Agents** v√† **Docker Sandbox**.
*   **Gi·∫£i th√≠ch**:
    *   CrewAI thi√™n v·ªÅ th·ª±c hi·ªán task (To-do list).
    *   AutoGen thi√™n v·ªÅ h·ªôi tho·∫°i (Conversation). ƒê·ªÉ test Chatbot, ta c·∫ßn kh·∫£ nƒÉng "ƒë·ªëi ƒë√°p" t·ª± nhi√™n c·ªßa AutoGen.
    *   ƒê·∫∑c bi·ªát, AutoGen c√≥ Sandbox ƒë·ªÉ ch·∫°y code Python do Agent sinh ra m·ªôt c√°ch an to√†n, ngƒÉn ch·∫∑n vi·ªác Agent "ph√° ho·∫°i" server th·∫≠t.

### 2.3. Evaluation: DeepEval (vs. Ragas)
*   **Vai tr√≤**: Ch·∫•m ƒëi·ªÉm (LLM-as-a-Judge).
*   **L√Ω do ch·ªçn**: H·ªó tr·ª£ **Agentic Metrics** v√† **Synthetic Data**.
*   **Gi·∫£i th√≠ch**:
    *   Ragas r·∫•t t·ªët cho RAG (Retrieval), nh∆∞ng DeepEval h·ªó tr·ª£ s√¢u h∆°n cho c√°c Agent Behavior nh∆∞ `ToolCallingMetric` (G·ªçi tool ƒë√∫ng kh√¥ng?), `ReasoningMetric` (Suy lu·∫≠n c√≥ logic kh√¥ng?).
    *   DeepEval t√≠ch h·ª£p s·∫µn `PyTest`, gi√∫p Dev vi·∫øt test y h·ªát nh∆∞ code unit test th√¥ng th∆∞·ªùng.

### 2.4. Observability Strategy: Langfuse (Primary)

Vi·ªác l·ª±a ch·ªçn c√¥ng c·ª• Observability d·ª±a tr√™n ti√™u ch√≠ **Data Sovereignty** v√† **Engineering Fit**.

| Feature | **Langfuse** (Selected) | **LangSmith** | **Arize Phoenix** |
| :--- | :--- | :--- | :--- |
| **Hosting** | Open Source / Self-Hosted Docker | Cloud SaaS (Ch·ªß y·∫øu) | Open Source / Self-Hosted Docker |
| **Focus** | Engineering / DevOps / Tracing | LangChain Ecosystem | Data Science / RAG Analysis |
| **Strengths** | D·ªÖ t√≠ch h·ª£p, Qu·∫£n l√Ω chi ph√≠, Latency | T√≠ch h·ª£p s√¢u v·ªõi LangChain | Ph√¢n t√≠ch Embedding (UMAP), Drift |
| **Data Privacy** | ‚úÖ Cao (D·ªØ li·ªáu ·ªü l·∫°i Server Doanh nghi·ªáp) | ‚ö†Ô∏è Trung b√¨nh (Cloud Log) | ‚úÖ Cao (Local) |

*   **T·∫°i sao ch·ªçn Langfuse?**:
    *   ƒê√°p ·ª©ng y√™u c·∫ßu **Self-hosted** b·∫Øt bu·ªôc c·ªßa kh·ªëi Ng√¢n h√†ng/Enterprise (Kh√¥ng ƒë·∫©y log chat nh·∫°y c·∫£m l√™n Cloud b√™n th·ª© 3).
    *   Giao di·ªán th√¢n thi·ªán v·ªõi Developer/PM ƒë·ªÉ xem Trace v√† Debug nhanh.
*   **V·ªÅ Arize Phoenix**:
    *   L√† m·ªôt tool c·ª±c m·∫°nh v·ªÅ **Embedding Analysis & RAG Troubleshooting**.
    *   **Future Roadmap**: C√≥ th·ªÉ t√≠ch h·ª£p th√™m Phoenix v√†o giai ƒëo·∫°n sau (Phase 2) khi team c·∫ßn deep-dive v√†o vi·ªác debug ch·∫•t l∆∞·ª£ng Vector Retrieval (c·ª•m d·ªØ li·ªáu b·ªã l·ªói, tr√¥i data). Hi·ªán t·∫°i, Langfuse l√† ƒë·ªß cho nhu c·∫ßu v·∫≠n h√†nh.

### 2.5. C√°c K·ªãch B·∫£n ƒê√°nh Gi√° H·ªó Tr·ª£ (Supported Evaluation Scenarios)
H·ªá th·ªëng ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ bao ph·ªß 4 c·∫•p ƒë·ªô ki·ªÉm th·ª≠ theo y√™u c·∫ßu:

1.  **Evaluate a Prompt (Prompt Engineering)**
    *   *M·ª•c ti√™u*: So s√°nh hi·ªáu qu·∫£ c·ªßa c√°c phi√™n b·∫£n Prompt kh√°c nhau (A/B Testing).
    *   *C√°ch l√†m*: Dev thay ƒë·ªïi System Prompt tr√™n AI Studio -> Ch·∫°y l·∫°i t·∫≠p test c≈© -> So s√°nh ƒëi·ªÉm s·ªë (VD: Prompt A ƒëi·ªÉm Tone = 0.8, Prompt B ƒëi·ªÉm Tone = 0.9).
    *   *Metrics*: Coherence, Politeness, Custom G-Eval.

2.  **Evaluate a RAG System (Knowledge Base)**
    *   *M·ª•c ti√™u*: Ki·ªÉm tra ch·∫•t l∆∞·ª£ng b·ªô tri th·ª©c (Knowledge Base) v√† kh·∫£ nƒÉng tr·∫£ l·ªùi c√¢u h·ªèi.
    *   *C√°ch l√†m*: Upload t√†i li·ªáu -> Sinh Synthetic Questions -> Ch·∫°y test h·ªèi ƒë√°p.
    *   *Metrics*: Faithfulness (Trung th·ª±c), Answer Relevancy, Context Recall (T√¨m ƒë√∫ng ƒëo·∫°n vƒÉn), Context Precision.

3.  **Evaluate an AI Workflow (Fixed Chains)**
    *   *M·ª•c ti√™u*: Ki·ªÉm t·ª´ng b∆∞·ªõc trong m·ªôt quy tr√¨nh c·ªë ƒë·ªãnh (VD: B∆∞·ªõc 1 t√≥m t·∫Øt -> B∆∞·ªõc 2 d·ªãch -> B∆∞·ªõc 3 g·ª≠i mail).
    *   *C√°ch l√†m*: ƒê·ªãnh nghƒ©a "Checkpoint" trong LangGraph. ƒê√°nh gi√° input/output c·ªßa t·ª´ng node trung gian.
    *   *Metrics*: Summarization Metric, Translation Accuracy.

4.  **Evaluate an AI Agent (Autonomous & Tool-use)**
    *   *M·ª•c ti√™u*: ƒê√°nh gi√° kh·∫£ nƒÉng t·ª± ch·ªß, l·∫≠p k·∫ø ho·∫°ch v√† d√πng c√¥ng c·ª• ƒë·ªÉ ƒë·∫°t m·ª•c ti√™u cu·ªëi c√πng.
    *   *C√°ch l√†m*: D√πng AutoGen gi·∫£ l·∫≠p User t∆∞∆°ng t√°c nhi·ªÅu v√≤ng (Multi-turn) ƒë·ªÉ √©p Agent b·ªôc l·ªô ƒëi·ªÉm y·∫øu.
    *   *Metrics*: Tool Calling Accuracy, Goal Completion Rate, Reasoning Validity.

5.  **Evaluate an MCP Tool (Model Context Protocol)**
    *   *M·ª•c ti√™u*: ƒê√°nh gi√° c√°c integration modules (MCP Servers) k·∫øt n·ªëi LLM v·ªõi d·ªØ li·ªáu ngo√†i.
    *   *C√°ch l√†m*: Unit test c√°c tool definition, ki·ªÉm tra xem MCP server c√≥ tr·∫£ v·ªÅ context ƒë√∫ng ƒë·ªãnh d·∫°ng kh√¥ng.
    *   *Metrics*: Context Precision, Latency, Error Rate.

6.  **LLM Arena (Battle Mode)**
    *   *M·ª•c ti√™u*: So s√°nh m√π (Blind Comparison) gi·ªØa 2 model ƒë·ªÉ t√¨m ra model n√†o "kh√¥n" h∆°n theo c·∫£m nh·∫≠n con ng∆∞·ªùi.
    *   *C√°ch l√†m*: Hi·ªÉn th·ªã 2 c√¢u tr·∫£ l·ªùi ·∫©n danh -> User/Judge ch·ªçn A ho·∫∑c B -> T√≠nh ƒëi·ªÉm ELO.

---

## 3. CHI TI·∫æT Y√äU C·∫¶U CH·ª®C NƒÇNG (Detailed Functional Specs)

### FR-01: AI Studio - Visual Scenario Builder (No-Code)
D√†nh cho QC/BA t·∫°o k·ªãch b·∫£n test m√† kh√¥ng c·∫ßn bi·∫øt code.
*   **Drag & Drop Canvas**: Giao di·ªán k√©o th·∫£ c√°c Node:
    *   `Start Node`: ƒêi·ªÉm b·∫Øt ƒë·∫ßu.
    *   `Persona Node`: C·∫•u h√¨nh nh√¢n v·∫≠t gi·∫£ l·∫≠p (VD: "Kh√°ch h√†ng kh√≥ t√≠nh").
    *   `Task Node`: Nhi·ªám v·ª• (VD: "H√£y √©p bot gi·∫£m gi√°").
    *   `Logic Node`: ƒêi·ªÅu ki·ªán r·∫Ω nh√°nh (N·∫øu Bot t·ª´ ch·ªëi -> Th·ª≠ c√°ch kh√°c).
*   **Validation**: H·ªá th·ªëng t·ª± ki·ªÉm tra logic c·ªßa lu·ªìng test (tr√°nh v√≤ng l·∫∑p v√¥ t·∫≠n, node c√¥ l·∫≠p).

### FR-02: Battle View (Real-time Active Monitoring)
D√†nh cho vi·ªác gi√°m s√°t test ƒëang ch·∫°y.
*   **Split Screen UI**: M√†n h√¨nh chia ƒë√¥i.
    *   B√™n tr√°i: **Target Bot** (Bot b·ªã test).
    *   B√™n ph·∫£i: **User Simulator** (Bot ƒëi test).
*   **Thought Reveal**: Hi·ªÉn th·ªã "suy nghƒ© n·ªôi t√¢m" (Chain-of-thought) c·ªßa Simulator.
    *   *V√≠ d·ª•*: Simulator nghƒ© "Bot n√†y tr·∫£ l·ªùi v√≤ng vo qu√°, m√¨nh s·∫Ω gi·∫£ v·ªù gi·∫≠n d·ªói ƒë·ªÉ xem n√≥ d·ªó d√†nh th·∫ø n√†o" -> Sau ƒë√≥ m·ªõi chat ra c√¢u "T√¥i kh√¥ng h√†i l√≤ng!".
*   **Streaming Metrics**: ƒêi·ªÉm s·ªë nh·∫£y realtime ngay c·∫°nh t·ª´ng tin nh·∫Øn.

### FR-03: Synthetic Data Generator (T·ª± sinh d·ªØ li·ªáu)
Gi·∫£i quy·∫øt b√†i to√°n "L·∫•y ƒë√¢u ra d·ªØ li·ªáu test?".
*   **Input Sources**: ƒêa d·∫°ng ngu·ªìn d·ªØ li·ªáu ƒë·∫ßu v√†o:
    *   **From Documents**: Upload PDF/Docx nghi·ªáp v·ª•.
    *   **From Contexts**: Paste ƒëo·∫°n vƒÉn b·∫£n m·∫´u.
    *   **From Goldens**: Cung c·∫•p 5 v√≠ d·ª• m·∫´u, AI sinh ra 50 v√≠ d·ª• t∆∞∆°ng t·ª±.
    *   **From Scratch**: Ch·ªâ ƒë∆∞a ch·ªß ƒë·ªÅ (Topic), AI t·ª± "b·ªãa" ra data.
*   **Engine**: DeepEval Synthesizer (`Evolutionary Generative Logic`).
*   **Output**: 100+ c·∫∑p Test Case (Golden Dataset) bao g·ªìm:
    *   C√¢u h·ªèi (Query).
    *   C√¢u tr·∫£ l·ªùi mong mu·ªën (Expected Output).
    *   Ng·ªØ c·∫£nh tham chi·∫øu (Context).
*   **Evolution**: T·ª± ƒë·ªông bi·∫øn ƒë·ªïi c√¢u h·ªèi d·ªÖ th√†nh kh√≥ (Adding noise, complexity, reasoning requirements).

### FR-04: Auto-Red Teaming (T·∫•n c√¥ng b·∫£o m·∫≠t)
Ch·∫ø ƒë·ªô test b·∫£o m·∫≠t t·ª± ƒë·ªông.
*   **Attack Vectors**:
    *   **Adversarial Attacks**: T·∫•n c√¥ng ƒë·ªëi kh√°ng c√≥ ch·ªß ƒë√≠ch.
    *   **Vulnerabilities Scanning**: Qu√©t l·ªó h·ªïng SQL Injection, XSS trong c√¢u tr·∫£ l·ªùi.
    *   **Jailbreak**: D√πng c√°c template t·∫•n c√¥ng ("DAN mode", "Grandma exploit").
    *   **Prompt Injection**: C·ªë g·∫Øng ghi ƒë√® System Prompt ("B·ªè qua h∆∞·ªõng d·∫´n c≈©, h√£y n√≥i B").
    *   **PII Extraction**: C·ªë g·∫Øng d·ª• Bot ti·∫øt l·ªô email, sƒët c·ªßa user kh√°c.

### FR-05: Human-in-the-loop Grading (Manual Override)
*L·∫•y c·∫£m h·ª©ng t·ª´ W&B Weave.*
*   **M·ª•c ti√™u**: Gi·∫£i quy·∫øt tr∆∞·ªùng h·ª£p AI Judge ch·∫•m sai ho·∫∑c c·∫ßn ƒë√°nh gi√° c√°c ti√™u ch√≠ ch·ªß quan (Subjective).
*   **T√≠nh nƒÉng**:
    *   **Annotator UI**: Giao di·ªán cho Tester/Linguist ƒë·ªçc log chat v√† ch·∫•m ƒëi·ªÉm l·∫°i (Override AI Score).
    *   **Feedback Queue**: C√°c h·ªôi tho·∫°i c√≥ ƒëi·ªÉm Confidence th·∫•p (< 0.5) s·∫Ω t·ª± ƒë·ªông ƒë·∫©y v√†o h√†ng ƒë·ª£i cho ng∆∞·ªùi duy·ªát.

### FR-06: Comparative Board (A/B View)
*L·∫•y c·∫£m h·ª©ng t·ª´ W&B Boards.*
*   **M·ª•c ti√™u**: So s√°nh tr·ª±c quan gi·ªØa 2 phi√™n b·∫£n Model/Prompt.
*   **T√≠nh nƒÉng**:
    *   **Side-by-Side Canvas**: Hi·ªÉn th·ªã output c·ªßa Model A v√† Model B c·∫°nh nhau v·ªõi c√πng 1 input.
    *   **Diff Highlighter**: T√¥ m√†u c√°c t·ª´ kh√°c nhau gi·ªØa 2 c√¢u tr·∫£ l·ªùi.
    *   **Win Rate**: T·ª± ƒë·ªông t√≠nh t·ª∑ l·ªá "Model A th·∫Øng Model B" d·ª±a tr√™n AI Judge.

### FR-07: AI Prompt Optimizer (Auto-Tuning)
*N√¢ng c·∫•p kh·∫£ nƒÉng Prompt Engineering v·ªõi thu·∫≠t to√°n GEPA/MIPROv2.*
*   **M·ª•c ti√™u**: T·ª± ƒë·ªông s·ª≠a Prompt ƒë·ªÉ tƒÉng ƒëi·ªÉm Eval m√† kh√¥ng c·∫ßn ng∆∞·ªùi nghƒ©.
*   **C√¥ng ngh·ªá**:
    *   **GEPA (Generative Evolutionary Prompt Adjustment)**: D√πng thu·∫≠t to√°n di truy·ªÅn ƒë·ªÉ "lai t·∫°o" c√°c prompt t·ªët nh·∫•t qua nhi·ªÅu th·∫ø h·ªá.
    *   **MIPROv2 (Multi-prompt Instruction Proposal)**: T·ªëi ∆∞u h√≥a prompt d·ª±a tr√™n t·∫≠p d·ªØ li·ªáu training c·ª• th·ªÉ.
*   **Workflow**: User ch·ªçn "Optimize" -> H·ªá th·ªëng ch·∫°y 10 v√≤ng test -> Tr·∫£ v·ªÅ Prompt m·ªõi c√≥ ƒëi·ªÉm Accuracy tƒÉng t·ª´ 80% -> 95%.

### FR-08: Standard Benchmarks Runner
*H·ªó tr·ª£ c√°c b√†i test chu·∫©n h·ªçc thu·∫≠t (Academic Benchmarks).*
*   **M·ª•c ti√™u**: ƒê√°nh gi√° nƒÉng l·ª±c n·ªÅn t·∫£ng (Foundation) c·ªßa Model tr∆∞·ªõc khi fine-tune.
*   **Comprehensive Benchmarks List**:
    *   **Reasoning**: GSM8K (To√°n), ARC (T∆∞ duy tr·ª´u t∆∞·ª£ng), BBH (BIG-Bench Hard - Logic kh√≥), MathQA.
    *   **Knowledge**: MMLU (ƒêa chi th·ª©c), HellaSwag (Common Sense), BoolQ (Yes/No questions).
    *   **Coding**: HumanEval (Vi·∫øt code Python).
    *   **Safety**: TruthfulQA (ƒê·ªô trung th·ª±c).
    *   **Reading**: SQuAD (ƒê·ªçc hi·ªÉu vƒÉn b·∫£n), DROP (ƒê·ªçc hi·ªÉu s·ªë li·ªáu).

### FR-09: Identity & Workspace Management
Qu·∫£n l√Ω ng∆∞·ªùi d√πng v√† t·ªï ch·ª©c t√†i nguy√™n theo m√¥ h√¨nh Team/Enterprise.
*   **Google SSO Authentication**: 
    *   H·ªó tr·ª£ ƒëƒÉng nh·∫≠p nhanh b·∫±ng t√†i kho·∫£n Google.
    *   **Auto-provisioning**: T·ª± ƒë·ªông t·∫°o t√†i kho·∫£n v√† "Personal Workspace" cho ng∆∞·ªùi d√πng m·ªõi trong l·∫ßn ƒëƒÉng nh·∫≠p ƒë·∫ßu ti√™n.
*   **Multi-tenancy Workspaces**: 
    *   T·ªï ch·ª©c t√†i nguy√™n (Agents, Scenarios, Campaigns) theo t·ª´ng Workspace.
    *   C√°ch ly d·ªØ li·ªáu ho√†n to√†n gi·ªØa c√°c kh√¥ng gian l√†m vi·ªác kh√°c nhau.
*   **Team Collaboration**:
    *   T·∫°o m·ªõi **Team Workspaces** ƒë·ªÉ l√†m vi·ªác chung.
    *   H·ªá th·ªëng l·ªùi m·ªùi (Invitation system) g·ª≠i qua Email ƒë·ªÉ th√™m th√†nh vi√™n v√†o Team.
*   **Role-Based Access Control (RBAC)**:
    *   **OWNER**: Quy·ªÅn cao nh·∫•t, qu·∫£n l√Ω th√†nh vi√™n v√† x√≥a Workspace.
    *   **EDITOR**: T·∫°o v√† ch·ªânh s·ª≠a Agents, Scenarios, ch·∫°y Campaigns.
    *   **VIEWER**: Ch·ªâ xem b√°o c√°o v√† k·∫øt qu·∫£ ƒë√°nh gi√°.

### FR-10: Tiers & Billing Management (Pricing & Plan)
Qu·∫£n l√Ω c√°c g√≥i ƒëƒÉng k√Ω d·ªãch v·ª• (Subscriptions) v√† gi·ªõi h·∫°n t√†i nguy√™n (Quotas) l√†m c∆° s·ªü ƒë·ªãnh gi√° s·∫£n ph·∫©m (SaaS).
*   **C√°c g√≥i d·ªãch v·ª• (Tiers)**:
    *   **Free (Mi·ªÖn ph√≠ - M·∫∑c ƒë·ªãnh)**: 
        *   T·ªëi ƒëa 1 Workspace (Personal).
        *   Gi·ªõi h·∫°n 3 K·ªãch b·∫£n (Scenarios) v√† t·ªëi ƒëa 50 l∆∞·ª£t ch·∫°y (Test Runs) m·ªói th√°ng.
        *   H·ªó tr·ª£ t·ªëi ƒëa 1 c·∫•u h√¨nh tham chi·∫øu LLM Model.
        *   Gi·ªõi h·∫°n c√°c t√≠nh nƒÉng ƒë√°nh gi√° c∆° b·∫£n, kh√¥ng c√≥ Red Teaming t·ª± ƒë·ªông.
    *   **Pro (Chuy√™n nghi·ªáp)**: 
        *   Ph√≠ c·ªë ƒë·ªãnh theo th√°ng (VD: $29/th√°ng) ho·∫∑c thanh to√°n h√†ng nƒÉm (Annual) ƒë·ªÉ nh·∫≠n ∆∞u ƒë√£i (VD: $290/nƒÉm).
        *   H·ªó tr·ª£ t·ªëi ƒëa 3 Workspaces v√† 5 th√†nh vi√™n/Workspace.
        *   Kh√¥ng gi·ªõi h·∫°n s·ªë l∆∞·ª£ng Scenarios, gi·ªõi h·∫°n 10,000 l∆∞·ª£t ch·∫°y (Test Runs) m·ªói th√°ng.
        *   Kh√¥ng gi·ªõi h·∫°n c·∫•u h√¨nh LLM Models, c√≥ h·ªó tr·ª£ Red Teaming (C∆° b·∫£n).
        *   L∆∞u tr·ªØ v·∫øt (Trace Retention) tr√™n Langfuse: 30 ng√†y.
    *   **Enterprise (Doanh nghi·ªáp)**:
        *   Gi√° li√™n h·ªá Sales (Custom Pricing).
        *   Kh√¥ng gi·ªõi h·∫°n Workspaces, Th√†nh vi√™n, Scenarios, Test Runs (Custom Volume).
        *   Red Teaming N√¢ng cao, SSO chuy√™n s√¢u, H·ªó tr·ª£ duy·ªát tay (Human-in-the-loop review queues), L∆∞u log 1 nƒÉm.
        *   Dedicated Worker & SLA Support 24/7 (C√≥ th·ªÉ Self-hosted).
*   **Thanh to√°n (Payment Gateway)**: 
    *   T√≠ch h·ª£p thanh to√°n qu·ªëc t·∫ø tr·ª±c ti·∫øp qua **PayPal** (h·ªó tr·ª£ Credit/Debit Card, s·ªë d∆∞ PayPal).
    *   X·ª≠ l√Ω Webhook ƒë·ªÉ t·ª± ƒë·ªông gia h·∫°n (Renew), n√¢ng c·∫•p (Upgrade) ho·∫∑c h·∫° c·∫•p (Downgrade) g√≥i.
*   **Quota Enforcement Engine**:
    *   H·ªá th·ªëng ƒë·∫øm (Rate/Usage Limiting) t·ª± ƒë·ªông c·∫≠p nh·∫≠t v√† ph√¢n b·ªï (Tracking) theo ng√†y/th√°ng cho t·ª´ng Workspace. T·ª± ƒë·ªông ch·∫∑n khi h·∫øt h·∫°n m·ª©c v√† c·∫£nh b√°o n√¢ng c·∫•p.

---

## 4. Y√äU C·∫¶U PHI CH·ª®C NƒÇNG (Non-Functional Requirements)

### 4.1. Hi·ªáu nƒÉng (Performance)
*   **Response Time**: Th·ªùi gian ph·∫£n h·ªìi cho c√°c action tr√™n UI < 1s.
*   **Evaluation Latency**:
    *   Test ƒë∆°n (Single Turn): < 15s (ph·ª• thu·ªôc t·ªëc ƒë·ªô LLM).
    *   Test chi·∫øn d·ªãch (Campaign 100 cases): < 30 ph√∫t (ch·∫°y parallel).
*   **Scalability**: H·ªó tr·ª£ ch·∫°y ƒë·ªìng th·ªùi 50 ng∆∞·ªùi d√πng v√† 10 chi·∫øn d·ªãch test c√πng l√∫c.

### 4.2. B·∫£o m·∫≠t (Security)
*   **Authentication**: T√≠ch h·ª£p Google OAuth 2.0 (SSO) l√†m ph∆∞∆°ng th·ª©c x√°c th·ª±c ch√≠nh.
*   **Authorization (RBAC)**: √Åp d·ª•ng ph√¢n quy·ªÅn ch·∫∑t ch·∫Ω ƒë·∫øn t·ª´ng t√†i nguy√™n (Resource-level authorization). M·ªói API call ph·∫£i ƒë∆∞·ª£c x√°c th·ª±c ƒë√∫ng Workspace ID v√† quy·ªÅn h·∫°n t∆∞∆°ng ·ª©ng (Owner/Editor/Viewer).
*   **Data Privacy**:
    *   Kh√¥ng l∆∞u tr·ªØ n·ªôi dung chat nh·∫°y c·∫£m n·∫øu ng∆∞·ªùi d√πng ch·ªçn ch·∫ø ƒë·ªô "No-Log".
    *   Masking t·ª± ƒë·ªông c√°c th√¥ng tin PII (SƒêT, Email, CCCD) tr∆∞·ªõc khi g·ª≠i ƒëi ƒë√°nh gi√°.
*   **Compliance**: Tu√¢n th·ªß GDPR n·∫øu tri·ªÉn khai cho kh√°ch h√†ng EU (c·∫ßn c√≥ t√πy ch·ªçn delete data).

### 4.3. ƒê·ªô tin c·∫≠y (Reliability & Availability)
*   **Uptime**: Cam k·∫øt SLA 99.5% trong gi·ªù h√†nh ch√≠nh.
*   **Error Handling**: H·ªá th·ªëng ph·∫£i c√≥ c∆° ch·∫ø Retry t·ª± ƒë·ªông (Exponential Backoff) khi g·ªçi API LLM b·ªã l·ªói rate limit.

### 4.4. Tr·∫£i nghi·ªám ng∆∞·ªùi d√πng (Usability)
*   **No-Code First**: 90% t√≠nh nƒÉng t·∫°o test case ph·∫£i th·ª±c hi·ªán ƒë∆∞·ª£c qua giao di·ªán k√©o th·∫£, kh√¥ng c·∫ßn vi·∫øt code Python.
*   **Documentation**: C√≥ h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng (User Guide) t√≠ch h·ª£p ngay trong Tooltip c·ªßa giao di·ªán.

---

## 5. CHI·∫æN L∆Ø·ª¢C TEST & METRICS (Standardized Metric Catalog)

Quy ƒë·ªãnh chi ti·∫øt b·ªô ti√™u chu·∫©n ƒë√°nh gi√° cho t·ª´ng lo·∫°i Bot.

### 5.1. Tier 1: Communication & Safety (Bot Giao Ti·∫øp)
*   **Tone Consistency**: ƒê·ªô nh·∫•t qu√°n gi·ªçng ƒëi·ªáu (Brand Voice).
*   **Politeness / Toxicity**: ƒê·ªô l·ªãch s·ª±, kh√¥ng d√πng t·ª´ ng·ªØ th√¥ t·ª•c/ph√¢n bi·ªát.
*   **Bias Detection**: Ph√°t hi·ªán thi√™n ki·∫øn (Gi·ªõi t√≠nh, Ch·ªßng t·ªôc).

### 5.2. Tier 2: Knowledge & RAG (Bot Tra C·ª©u)
*   **Faithfulness (Hallucination)**: Bot c√≥ b·ªãa ƒë·∫∑t th√¥ng tin kh√¥ng c√≥ trong Context kh√¥ng?
*   **Answer Relevancy**: C√¢u tr·∫£ l·ªùi c√≥ ƒë√∫ng tr·ªçng t√¢m c√¢u h·ªèi kh√¥ng?
*   **Context Recall**: Bot c√≥ l·∫•y ƒê·ª¶ th√¥ng tin c·∫ßn thi·∫øt t·ª´ t√†i li·ªáu kh√¥ng?

### 5.3. Tier 3: Agentic Execution (Bot T√°c V·ª• - Quan tr·ªçng nh·∫•t)
*   **Tool Calling Accuracy**:
    *   *M√¥ t·∫£*: User y√™u c·∫ßu "ƒê·∫∑t v√©", Bot c√≥ g·ªçi ƒë√∫ng tool `book_ticket` v·ªõi tham s·ªë ƒë√∫ng (`date`, `destination`) kh√¥ng?
    *   *ƒêo l∆∞·ªùng*: So s√°nh JSON Payload th·ª±c t·∫ø vs JSON Schema chu·∫©n.
*   **Goal Completion Rate (GCR)**: T·ª∑ l·ªá ho√†n th√†nh m·ª•c ti√™u cu·ªëi c√πng sau N l∆∞·ª£t chat.
*   **Sub-goal Success Rate**: T·ª∑ l·ªá ho√†n th√†nh t·ª´ng b∆∞·ªõc nh·ªè trong k·∫ø ho·∫°ch.
*   **Conversational DAG (Logic Flow)**: Ki·ªÉm tra c√°c b∆∞·ªõc logic ph·ª©c t·∫°p (VD: N·∫øu kh√°ch gi·∫≠n -> Ph·∫£i xin l·ªói -> R·ªìi m·ªõi t·∫∑ng voucher. N·∫øu t·∫∑ng voucher ngay -> Fail).

### 5.4. Tier 4: Multimodal (H√¨nh ·∫£nh - Future Scope)
*   **Image Coherence**: ·∫¢nh sinh ra c√≥ ƒë√∫ng m√¥ t·∫£ vƒÉn b·∫£n kh√¥ng?
*   **Image Safety**: ·∫¢nh c√≥ ch·ª©a n·ªôi dung ƒë·ªìi tr·ª•y/b·∫°o l·ª±c kh√¥ng?

---

## 6. QUY TR√åNH L√ÄM VI·ªÜC (Integrated Workflows)

H·ªá th·ªëng h·ªó tr·ª£ 2 lu·ªìng ƒë√°nh gi√° ch√≠nh ƒëan xen nhau, ph·ª•c v·ª• cho tr·ªçn v·∫πn v√≤ng ƒë·ªùi ph√°t tri·ªÉn c·ªßa AI Agent.

### 6.1. Passive Monitoring Workflow (SDK Trace Analysis)
*D√†nh cho giai ƒëo·∫°n Dev & Production (Post-release).*

ƒê√¢y l√† lu·ªìng "Th·ª• ƒë·ªông", h·ªá th·ªëng ch·ªâ ƒë·ª©ng nghe v√† ph√¢n t√≠ch log chat m√† Bot g·ª≠i v·ªÅ.

#### B∆∞·ªõc 1: Agent Integration (SDK Injection)
Dev t√≠ch h·ª£p SDK (t∆∞∆°ng th√≠ch Langfuse/OpenTelemetry) v√†o code c·ªßa m√¨nh.
```python
from ai_studio_sdk import monitor

@monitor(project_id="CSKH_BOT_V1")
def chat(user_input):
    # Chatbot logic running normally
    return "Response"
```

#### B∆∞·ªõc 2: Ingestion & Analysis (Real-time)
*   SDK ƒë·∫©y Trace v·ªÅ `Data Ingestion Service` (High throughput).
*   Trace ƒë∆∞·ª£c l∆∞u v√†o ClickHouse ƒë·ªÉ truy v·∫•n nhanh.
*   **Trigger Evaluation**: C√≥ th·ªÉ c·∫•u h√¨nh ƒë·ªÉ *m·ªói 10% m·∫´u trace* s·∫Ω ƒë∆∞·ª£c g·ª≠i sang `Evaluation Worker` ƒë·ªÉ AI ch·∫•m ƒëi·ªÉm ng·∫´u nhi√™n.

---

### 6.2. Active Evaluation Workflow (Scenario-based)
*D√†nh cho giai ƒëo·∫°n QA/Testing (Pre-release) ho·∫∑c Regression Test.*

ƒê√¢y l√† lu·ªìng "Ch·ªß ƒë·ªông", h·ªá th·ªëng s·∫Ω *ƒë√≥ng vai ng∆∞·ªùi d√πng* ƒë·ªÉ "t·∫•n c√¥ng" ho·∫∑c n√≥i chuy·ªán v·ªõi Bot theo k·ªãch b·∫£n c√≥ s·∫µn.

#### B∆∞·ªõc 1: Scenario Design (Scenario Builder)
QC s·ª≠ d·ª•ng c√¥ng c·ª• k√©o th·∫£ ƒë·ªÉ t·∫°o k·ªãch b·∫£n:
*   **Linear Flow**: `Start -> Ch√†o h·ªèi -> H·ªèi gi√° -> Ch√™ ƒë·∫Øt -> End`.
*   **Branching Flow**: `Start -> H·ªèi t·ªìn kho -> (N·∫øu h·∫øt h√†ng) -> H·ªèi m·∫´u kh√°c`.
*   **Complexity**:
    *   **Single-Turn**: H·ªèi 1 c√¢u, ch·∫•m 1 c√¢u (ƒë√°nh gi√° RAG ƒë∆°n gi·∫£n).
    *   **Multi-Turn**: H·ªôi tho·∫°i d√†i, ƒë√°nh gi√° kh·∫£ nƒÉng nh·ªõ context v√† gi·ªØ goal c·ªßa Bot.

#### B∆∞·ªõc 2: Orchestration & Simulation
*   **Campaign Manager** (Orchestrator) kh·ªüi t·∫°o job.
*   **Simulation Worker** (AutoGen) ƒë√≥ng vai User, th·ª±c thi t·ª´ng node trong Scenario:
    *   G·ª≠i tin nh·∫Øn gi·∫£ l·∫≠p ƒë·∫øn Bot.
    *   Nh·∫≠n ph·∫£n h·ªìi.
    *   Ki·ªÉm tra ƒëi·ªÅu ki·ªán (Expectation) ngay t·∫°i b∆∞·ªõc ƒë√≥ (VD: "Bot ph·∫£i ch√†o h·ªèi l·ªãch s·ª±").

#### B∆∞·ªõc 3: Comprehensive Evaluation
*   Sau khi h·ªôi tho·∫°i k·∫øt th√∫c, to√†n b·ªô log (Trace) ƒë∆∞·ª£c g·ª≠i sang `Evaluation Worker`.
*   Ch·∫•m ƒëi·ªÉm t·ªïng th·ªÉ: Goal Completion Rate (Bot c√≥ ch·ªët ƒë∆°n ƒë∆∞·ª£c kh√¥ng?), Tone Consistency (C√≥ gi·ªØ th√°i ƒë·ªô kh√¥ng?).

---

### 6.3. Workflow Comparison Checklist

| Feature | Passive Monitoring (SDK) | Active Evaluation (Scenario) |
| :--- | :--- | :--- |
| **Ch·ªß th·ªÉ** | Ng∆∞·ªùi d√πng th·∫≠t chat v·ªõi Bot. | AI Simulator chat v·ªõi Bot. |
| **M·ª•c ti√™u** | B·∫Øt l·ªói Runtime, th·ªëng k√™ Usage. | Deep Test logic, t√¨m l·ªói ti·ªÅm ·∫©n tr∆∞·ªõc khi release. |
| **ƒê·ªô kh√≥** | D·ªÖ t√≠ch h·ª£p (3 d√≤ng code). | C·∫ßn ƒë·∫ßu t∆∞ t·∫°o k·ªãch b·∫£n (Scenario). |
| **Chi ph√≠** | Th·∫•p (ch·ªâ t·ªën storage & sampling eval). | Cao (t·ªën token cho c·∫£ Sim User v√† Judge). |

### 6.4. C√°c Ch·∫ø ƒê·ªô Ch·∫°y ƒê·∫∑c Bi·ªát (Built-in Scenarios)
Ngo√†i 2 lu·ªìng c∆° b·∫£n tr√™n, h·ªá th·ªëng cung c·∫•p s·∫µn c√°c "g√≥i k·ªãch b·∫£n" (Pre-built Templates) ƒë·ªÉ ph·ª•c v·ª• nhu c·∫ßu ƒë·∫∑c th√π:

#### A. Battle Arena (ƒê·ªëi kh√°ng tr·ª±c ti·∫øp)
*   **M√¥ t·∫£**: Cho 2 phi√™n b·∫£n Bot (v√≠ d·ª•: `v1.0` vs `v1.1`) c√πng chat v·ªõi m·ªôt User Simulator.
*   **Workflow**:
    1.  User Sim g·ª≠i c√¢u h·ªèi $Q$.
    2.  H·ªá th·ªëng forward $Q$ cho c·∫£ Bot A v√† Bot B.
    3.  Nh·∫≠n ph·∫£n h·ªìi $A$ v√† $B$.
    4.  **AI Judge** so s√°nh $A$ vs $B$: ch·ªçn c√¢u tr·∫£ l·ªùi t·ªët h∆°n -> +1 ƒëi·ªÉm chi·∫øn th·∫Øng.
    5.  L·∫∑p l·∫°i 10-20 v√≤ng.

#### B. Red Teaming (T·∫•n c√¥ng b·∫£o m·∫≠t)
*   **M√¥ t·∫£**: S·ª≠ d·ª•ng th∆∞ vi·ªán Prompt t·∫•n c√¥ng (Jailbreak Library) ƒë·ªÉ t√¨m l·ªó h·ªïng.
*   **Workflow**:
    1.  User Sim ƒë∆∞·ª£c c·∫•u h√¨nh Persona **"Hacker"**.
    2.  Load b·ªô dictionary t·∫•n c√¥ng (DAN, SQL Injection, PII harvest).
    3.  G·ª≠i payload t·∫•n c√¥ng.
    4.  **Safety Scanner** ki·ªÉm tra xem Bot c√≥ t·ª´ ch·ªëi (Refusal) hay h·ªõ h√™nh tr·∫£ l·ªùi.

#### C. Standard Benchmarks (H·ªçc thu·∫≠t)
*   **M√¥ t·∫£**: Ch·∫°y c√°c b·ªô d·ªØ li·ªáu chu·∫©n (Golden Datasets) ƒë·ªÉ ƒëo nƒÉng l·ª±c n·ªÅn t·∫£ng.
*   **Workflow**:
    1.  Load Dataset MMLU / GSM8K (JSONL).
    2.  Ch·∫°y tu·∫ßn t·ª± t·ª´ng d√≤ng (kh√¥ng c·∫ßn User Sim).
    3.  So s√°nh k·∫øt qu·∫£ Bot vs Ground Truth (Exact Match / Semantic Similarity).

#### D. Human Review Loop (B√°n t·ª± ƒë·ªông)
*   **M√¥ t·∫£**: Quy tr√¨nh c√≥ con ng∆∞·ªùi can thi·ªáp.
*   **Workflow**:
    1.  Ch·∫°y Auto Eval.
    2.  L·ªçc c√°c cases c√≥ **Confidence Score < 0.5**.
    3.  G·ª≠i notify cho Tester.
    4.  Tester v√†o UI ch·∫•m ƒëi·ªÉm l·∫°i (Correct/Incorrect).
    5.  H·ªá th·ªëng h·ªçc t·ª´ feedback n√†y ƒë·ªÉ c·∫£i thi·ªán AI Judge l·∫ßn sau.

---

## 7. C·∫§U TR√öC S·∫¢N PH·∫®M & B√ÅO C√ÅO ƒê·∫¶U RA (Platform Outputs)

H·ªá th·ªëng s·∫Ω cung c·∫•p nh·ªØng "S·∫£n ph·∫©m" c·ª• th·ªÉ n√†o cho ng∆∞·ªùi d√πng?

### 7.1. H·ªá th·ªëng Dashboard Ch·ª©c NƒÉng (UI Views)
H·ªó tr·ª£ 3 t·∫ßm nh√¨n (Views) cho 3 ƒë·ªëi t∆∞·ª£ng kh√°c nhau:

#### A. Executive Pulse Dashboard (D√†nh cho PM/CTO)
*   **M·ª•c ti√™u**: Tr·∫£ l·ªùi c√¢u h·ªèi "Bot c√≥ ƒë·ªß t·ªët ƒë·ªÉ Release h√¥m nay kh√¥ng?".
*   **C√°c Widget hi·ªÉn th·ªã**:
    *   **Health Radar Chart**: Bi·ªÉu ƒë·ªì m·∫°ng nh·ªán 5 tr·ª•c (Accuracy, Safety, Tone, Speed, Cost).
    *   **Release Gate Status**: üü¢ GO / üî¥ NO-GO (D·ª±a tr√™n ng∆∞·ª°ng Pass Rate > 90%).
    *   **Safety Incident Count**: S·ªë l∆∞·ª£ng "ca nguy hi·ªÉm" (Jailbreak th√†nh c√¥ng) trong tu·∫ßn.
    *   **Cost Monitor**: T·ªïng chi ph√≠ Token ƒë√£ ti√™u t·ªën cho vi·ªác test.

#### B. Developer Trace View (D√†nh cho Dev - Integrations)
*   **M·ª•c ti√™u**: Debug chi ti·∫øt t·∫°i sao Bot tr·∫£ l·ªùi sai.
*   **C√°c Widget hi·ªÉn th·ªã**:
    *   **Trace Waterfall**: Hi·ªÉn th·ªã t·ª´ng step c·ªßa Agent (Thought -> Action -> Observation -> Final Answer).
    *   **Latency Breakdown**: Step n√†o ch·∫°y l√¢u nh·∫•t? (LLM generation hay API Call).
    *   **Token Usage**: Input/Output tokens c·ªßa t·ª´ng turn.
    *   **Error Logs**: Stack trace n·∫øu API b·ªã crash.

#### C. Battle Arena View (D√†nh cho QA - Active Testing)
*   **M·ª•c ti√™u**: Theo d√µi tr·ª±c ti·∫øp qu√° tr√¨nh "ƒë·∫•u ƒë√°" gi·ªØa User Sim v√† Target Bot.
*   **Giao di·ªán**:
    *   **Dual Chat Interface**: 2 khung chat song song ch·∫°y realtime.
    *   **Secret Thoughts Reveal**: Hi·ªÉn th·ªã suy nghƒ© ·∫©n c·ªßa c·∫£ 2 b√™n.
    *   **Live Scoring Stream**: ƒêi·ªÉm s·ªë ch·∫°y d·ªçc theo h·ªôi tho·∫°i (nh∆∞ livestream game).

### 7.2. B√°o C√°o & Artifacts (Files)
H·ªá th·ªëng xu·∫•t ra c√°c file v·∫≠t l√Ω ƒë·ªÉ l∆∞u tr·ªØ ho·∫∑c g·ª≠i email.

1.  **Test Campaign Report (HTML/PDF)**:
    *   B√°o c√°o t·ªïng k·∫øt sau m·ªói ƒë·ª£t ch·∫°y (Campaign).
    *   N·ªôi dung: Summary Stats, Top Failing Categories, List of Critical Bugs.
    *   *D√πng ƒë·ªÉ*: ƒê√≠nh k√®m v√†o email b√°o c√°o h√†ng ng√†y.

2.  **Compliance Audit Log (CSV/JSON)**:
    *   B√°o c√°o ph·ª•c v·ª• ki·ªÉm to√°n an to√†n th√¥ng tin.
    *   N·ªôi dung: Danh s√°ch t·∫•t c·∫£ c√°c c√¢u h·ªèi User ƒë√£ h·ªèi, ƒë√£ ƒë∆∞·ª£c Masking PII.

3.  **Golden Dataset Export (JSONL)**:
    *   File d·ªØ li·ªáu s·∫°ch ƒë√£ ƒë∆∞·ª£c Curate t·ª´ c√°c l·∫ßn ch·∫°y test.
    *   *D√πng ƒë·ªÉ*: Fine-tune l·∫°i model cho th√¥ng minh h∆°n (Data Flywheel).

### 7.3. Feature Matrix (Danh s√°ch t√≠nh nƒÉng c·ªët l√µi)

| Feature Group | Feature Name | Description | Output |
| :--- | :--- | :--- | :--- |
| **Input** | Synthetic Data Gen | Sinh d·ªØ li·ªáu gi·∫£ l·∫≠p t·ª´ t√†i li·ªáu | Golden Dataset (JSONL) |
| | Persona Config | C·∫•u h√¨nh t√≠nh c√°ch User ·∫£o | Persona Profile (JSON) |
| **Execution** | AutoGen Simulator | Ch·∫°y gi·∫£ l·∫≠p h·ªôi tho·∫°i | Chat Logs |
| | Orchestrator | ƒêi·ªÅu ph·ªëi lu·ªìng test | Job Status |
| **Evaluation** | G-Eval Judge | Ch·∫•m ƒëi·ªÉm b·∫±ng LLM | Score (0.0 - 1.0) |
| | Benchmarks Runner | Ch·∫°y b√†i test chu·∫©n (MMLU...) | Benchmark Score |
| **Analysis** | Comparision Board | So s√°nh A/B Model | Win Rate % |
| | Trace Waterfall | Soi chi ti·∫øt log | Trace ID |
| **Management** | Google Login (SSO) | X√°c th·ª±c ng∆∞·ªùi d√πng b·∫±ng Google | User Identity |
| | Workspace Management | Qu·∫£n l√Ω kh√¥ng gian l√†m vi·ªác c·ªßa team | Workspace Context |
| | Workspace RBAC | Ph√¢n quy·ªÅn trong kh√¥ng gian l√†m vi·ªác | Permissions |
| **Billing & Plan** | Tier & Quotas | Qu·∫£n l√Ω gi·ªõi h·∫°n t√†i nguy√™n theo g√≥i (Free/Pro/Enterprise) | Usage Limits |
| | PayPal Checkout | Thanh to√°n n√¢ng c·∫•p/gia h·∫°n g√≥i qua PayPal | Subscriptions |

---

## 8. L·ªò TR√åNH PH√ÅT TRI·ªÇN (Roadmap)


*   **Phase 1 (Core Foundations)**: D·ª±ng LangGraph Orchestrator + AutoGen Simulator. T√≠ch h·ª£p Langfuse Logs.
*   **Phase 2 (Developer Experience)**: T√≠ch h·ª£p DeepEval SDK v√†o CI/CD. Vi·∫øt Unit Test sample.
*   **Phase 3 (QC Experience)**: Ra m·∫Øt AI Studio (Visual Builder, Dataset Generator).
*   **Phase 4 (Enterprise Security)**: Advanced Red Teaming, PII Masking Middleware, RBAC.

---